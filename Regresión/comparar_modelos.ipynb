{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://machinelearningmastery.com/wp-content/uploads/2016/03/Compare-Machine-Learning-Algorithms.png\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2023\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Comparación de modelos de regresión</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que aprendimos a crear los modelos de machine learning ¿qué hacemos con ellos?\n",
    "\n",
    "Comparar varios modelos de machine learning para problemas de regresión es necesario para poder encontrar cuál de todos los modelos es el más eficiente y tiene los resultados más precisos. \n",
    "\n",
    "Hay muchos criterios para comparar los modelos. \n",
    "\n",
    "Recordando que si la **variable de respuesta es continua** entonces, este es un problema de **regresión** y tenemos que usar modelos de regresión para estimar los valores predichos. \n",
    "\n",
    "Como vimos, hay muchos modelos de regresión candidatos. Nuestra tarea es encontrar el que sirva a nuestro propósito.\n",
    "\n",
    "Vamos a comparar los siguientes modelos:\n",
    "- Regresión lineal múltiple\n",
    "- Regresión Ridge\n",
    "- Árbol de decisión\n",
    "- Bosques Aleatorios\n",
    "- SVR\n",
    "- Redes Neuronales\n",
    "\n",
    "\n",
    "Vamos a utilizar varias métricas para comparar los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Performance (Regresión)\n",
    "\n",
    "**Error Absoluto Medio (Mean Absolute Error - MAE)**\n",
    "\n",
    "Si $y$ es la variable de respuesta y $\\hat{y}$ es la predicción, entonces el MAE es el error entre estos pares ($y$,$\\hat{y}$) de variables y se calcula de la forma:\n",
    "\n",
    "$$MAE = \\frac{\\sum_{i=1}^{n}|y_{i}-\\hat{y}_{i}|}{n}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Mide el promedio del error absoluto entre los valores reales y las predicciones\n",
    "\n",
    "*Ventajas*\n",
    "- Es una métrica independiente de la escala, lo que significa que está en las mismas unidades de las variables originales. \n",
    "- Fácil de interpretar\n",
    "- Es buena opción si no nos importan los valores atípicos\n",
    "\n",
    "*Desventajas*\n",
    "- Se les da la misma importancia (peso) a todos los errores\n",
    "- Es insensible a valores atípicos\n",
    "\n",
    "\n",
    "\n",
    "**Error Cuadrático Medio (Mean Square Error - MSE)**\n",
    "\n",
    "\n",
    "$$MSE = \\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}}{n}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "El MSE calcula el promedio de los cuadrados del error entre los valores verdaderos y los valores estimados\n",
    "\n",
    "*Ventajas*\n",
    "- Función diferenciable\n",
    "- El efecto de errores más grandes se vuelve más pronunciado que los errores más pequeños\n",
    "\n",
    "*Desventajas*\n",
    "- Tiene diferentes unidades que los valores reales\n",
    "\n",
    "\n",
    "**Diferencia entre el MAE y el MSE**\n",
    "\n",
    "La gran diferencia es cómo responden a errores más grandes. \n",
    "\n",
    "Depende mucho de la decisión del negocio y el costo asociado a los errores. \n",
    "     \n",
    " **R^2**\n",
    " \n",
    " $$R^{2}=1-\\frac{SS_{res}}{SS_{Tot}}= \\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}}{\\sum_{i=1}^{n}(y_{i}-\\bar{y}_{i})^{2}}$$\n",
    " \n",
    " *¿Qué hace?*\n",
    "- Explica la proporción de la varianza de la salida (\"Y\") que puede ser explicada por los predictores (\"X\")\n",
    "\n",
    "*Desventajas*\n",
    "- Siempre incrementa añadiendo más variables independientes (X), lo cual es una desventaja porque esas variables pueden no ser importantes para el modelo\n",
    "\n",
    "*Ventajas*\n",
    "- Es una métrica relativa que se usa para comparar varios modelos que fueron entrenados con los mismos datos\n",
    "\n",
    "     \n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los Datos\n",
    "\n",
    "Tenemos un dataset de personas que tienen un carro y lo quieren vender. Se tienen las siguientes variables:\n",
    "\n",
    "- Age \n",
    "- Gender\n",
    "- Miles: promedio de millas manejadas por día\n",
    "- Debt\n",
    "- Income\n",
    "- **Sales**\n",
    "\n",
    "Basados en esas variables, queremos predecir el valor potencial de venta de un carro, por lo que variable a predecir es \"Sales\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\francisco\\anaconda3\\lib\\site-packages (1.26.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.2-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     -------------------------------------- 15.8/15.8 MB 660.7 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "Successfully installed numpy-1.26.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas 2.0.3 requires tzdata>=2022.1, which is not installed.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "xarray-einstats 0.6.0 requires xarray>=2022.09.0, but you have xarray 0.20.1 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.2 which is incompatible.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.2 which is incompatible.\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.2 which is incompatible.\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.9.1 which is incompatible.\n",
      "pymc 5.9.2 requires arviz>=0.13.0, but you have arviz 0.12.1 which is incompatible.\n",
      "numba 0.58.0 requires numpy<1.26,>=1.21, but you have numpy 1.26.2 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Selección de variables\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "#árbol de decisión\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Bosque aleatorio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Maquina de Vector Soporte (SVR)\n",
    "from sklearn.svm import SVR\n",
    "#Redes Neuronales\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import SGD, Adam\n",
    "#XGboost\n",
    "import xgboost as xgb\n",
    "\n",
    "#métricas de performance\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error, r2_score\n",
    "\n",
    "#Cross validation y train-test split\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "ruta_csv = r\"C:\\Users\\Francisco\\Downloads\\lab 3\\Regresión\\carros.csv\"\n",
    "\n",
    "# Leer el archivo CSV\n",
    "datos = pd.read_csv(ruta_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>miles</th>\n",
       "      <th>debt</th>\n",
       "      <th>income</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4099</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>41576</td>\n",
       "      <td>6215</td>\n",
       "      <td>27754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>43172</td>\n",
       "      <td>7626</td>\n",
       "      <td>28256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6979</td>\n",
       "      <td>8071</td>\n",
       "      <td>4438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  miles   debt  income  sales\n",
       "0   28       0     23      0    4099    620\n",
       "1   26       0     27      0    2677   1792\n",
       "2   30       1     58  41576    6215  27754\n",
       "3   26       1     25  43172    7626  28256\n",
       "4   20       1     17   6979    8071   4438"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tamaño de los datos\n",
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores_Nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miles</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Valores_Nulos\n",
       "age                 0\n",
       "gender              0\n",
       "miles               0\n",
       "debt                0\n",
       "income              0\n",
       "sales               0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisamos si hay datos nulos\n",
    "missing = pd.DataFrame(datos.isnull().sum(),columns=['Valores_Nulos'])\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "In FT2Font: Can not load face (error code 0x55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19648\\1045376246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Creamos gráficos básicos de los datos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'miles'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'debt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'income'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag_kind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"kde\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mpairplot\u001b[1;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, corner, dropna, plot_kws, diag_kws, grid_kws, size)\u001b[0m\n\u001b[0;32m   2094\u001b[0m     \u001b[1;31m# Set up the PairGrid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2095\u001b[0m     \u001b[0mgrid_kws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"diag_sharey\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"hist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2096\u001b[1;33m     grid = PairGrid(data, vars=vars, x_vars=x_vars, y_vars=y_vars, hue=hue,\n\u001b[0m\u001b[0;32m   2097\u001b[0m                     \u001b[0mhue_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhue_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2098\u001b[0m                     height=height, aspect=aspect, dropna=dropna, **grid_kws)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, hue, hue_order, palette, hue_kws, vars, x_vars, y_vars, corner, diag_sharey, height, aspect, layout_pad, despine, dropna, size)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdespine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m             \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdespine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mtight_layout\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tight_layout_pad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tight_layout_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_figure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     def add_legend(self, legend_data=None, title=None, label_order=None,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mtight_layout\u001b[1;34m(self, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m   3222\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_draw_disabled\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3224\u001b[1;33m             kwargs = get_tight_layout_figure(\n\u001b[0m\u001b[0;32m   3225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplotspec_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3226\u001b[0m                 pad=pad, h_pad=h_pad, w_pad=w_pad, rect=rect)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\tight_layout.py\u001b[0m in \u001b[0;36mget_tight_layout_figure\u001b[1;34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m    318\u001b[0m             slice(ss.colspan.start * div_col, ss.colspan.stop * div_col)))\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     kwargs = _auto_adjust_subplotpars(fig, renderer,\n\u001b[0m\u001b[0;32m    321\u001b[0m                                       \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_nrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_ncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                                       \u001b[0mspan_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspan_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\tight_layout.py\u001b[0m in \u001b[0;36m_auto_adjust_subplotpars\u001b[1;34m(fig, renderer, shape, span_pairs, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                     \u001b[0mbb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfor_layout_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mbb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4636\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4637\u001b[1;33m                     bb_yaxis = self.yaxis.get_tightbbox(\n\u001b[0m\u001b[0;32m   4638\u001b[0m                         renderer, for_layout_only=for_layout_only)\n\u001b[0;32m   4639\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;31m# go back to just this axis's tick labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2347\u001b[0m         \u001b[1;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m         \u001b[1;31m# that have been set by `fig.align_ylabels()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2349\u001b[1;33m         \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2350\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_position\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1879\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{axis_name}axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m             \u001b[0mtlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m             \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# Full vertical extent of font, including ascenders and descenders:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[0m\u001b[0;32m    310\u001b[0m             \u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             ismath=\"TeX\" if self.get_usetex() else False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# width and height of unrotated string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[1;34m(self, prop)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m    303\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[1;34m(filename, hinting_factor)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.hinting_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;31m# also key on the thread ID to prevent segfaults with multi-threading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m     return _get_font(filename, hinting_factor,\n\u001b[0m\u001b[0;32m   1425\u001b[0m                      \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.kerning_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m                      thread_id=threading.get_ident())\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m_get_font\u001b[1;34m(filename, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m     return ft2font.FT2Font(\n\u001b[0m\u001b[0;32m   1406\u001b[0m         filename, hinting_factor, _kerning_factor=_kerning_factor)\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: In FT2Font: Can not load face (error code 0x55)"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "In FT2Font: Can not load face (error code 0x55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2293\u001b[0m                 )\n\u001b[0;32m   2294\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_draw_disabled\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2295\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2836\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2837\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   2838\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[0;32m   2839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3089\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3091\u001b[1;33m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   3092\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[0;32m   3093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0m\u001b[0;32m   1160\u001b[0m                                                                 renderer)\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m             \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# Full vertical extent of font, including ascenders and descenders:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[0m\u001b[0;32m    310\u001b[0m             \u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             ismath=\"TeX\" if self.get_usetex() else False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# width and height of unrotated string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[1;34m(self, prop)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m    303\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[1;34m(filename, hinting_factor)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.hinting_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;31m# also key on the thread ID to prevent segfaults with multi-threading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m     return _get_font(filename, hinting_factor,\n\u001b[0m\u001b[0;32m   1425\u001b[0m                      \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.kerning_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m                      thread_id=threading.get_ident())\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m_get_font\u001b[1;34m(filename, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m     return ft2font.FT2Font(\n\u001b[0m\u001b[0;32m   1406\u001b[0m         filename, hinting_factor, _kerning_factor=_kerning_factor)\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: In FT2Font: Can not load face (error code 0x55)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1250x1250 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creamos gráficos básicos de los datos\n",
    "sns.pairplot(datos[['age', 'miles', 'debt', 'income', 'sales']], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.20</td>\n",
       "      <td>Symmetric distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>Symmetric distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miles</th>\n",
       "      <td>2.18</td>\n",
       "      <td>Highly Skewed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Highly Skewed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>Symmetric distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.49</td>\n",
       "      <td>Symmetric distribution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value                skewness\n",
       "age      0.20  Symmetric distribution\n",
       "gender  -0.05  Symmetric distribution\n",
       "miles    2.18           Highly Skewed\n",
       "debt     1.34           Highly Skewed\n",
       "income  -0.11  Symmetric distribution\n",
       "sales    0.49  Symmetric distribution"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de la asimetria con pandas\n",
    "skewness = round(datos.skew(),2)\n",
    "skewness = skewness.to_frame()\n",
    "skewness = skewness.rename(columns={0: \"value\"}) \n",
    "\n",
    "def f(x):\n",
    "    if x['value'] < -1 or x['value'] > 1: return 'Highly Skewed'\n",
    "    elif (x['value']<=0 and x['value']>=-0.5) or (x['value'] >=0 and x['value']<=0.5):\n",
    "        return 'Symmetric distribution'\n",
    "    else: return 'Moderately skewed'\n",
    "    \n",
    "skewness['skewness'] = skewness.apply(f, axis=1)\n",
    "\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos no están tan sesgados, por lo que podemos dejarlos de esta manera y no transformar los atípicos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>963.0</td>\n",
       "      <td>37.971963</td>\n",
       "      <td>12.290838</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>963.0</td>\n",
       "      <td>0.512980</td>\n",
       "      <td>0.500091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miles</th>\n",
       "      <td>963.0</td>\n",
       "      <td>27.704050</td>\n",
       "      <td>13.378181</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt</th>\n",
       "      <td>963.0</td>\n",
       "      <td>14109.004154</td>\n",
       "      <td>18273.702481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>6236.0</td>\n",
       "      <td>16686.0</td>\n",
       "      <td>59770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>963.0</td>\n",
       "      <td>6176.047767</td>\n",
       "      <td>3260.670142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3506.5</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>8649.5</td>\n",
       "      <td>11970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>963.0</td>\n",
       "      <td>11689.860852</td>\n",
       "      <td>8986.896921</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3554.0</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>19245.0</td>\n",
       "      <td>29926.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count          mean           std    min     25%     50%      75%  \\\n",
       "age     963.0     37.971963     12.290838   19.0    27.0    37.0     49.0   \n",
       "gender  963.0      0.512980      0.500091    0.0     0.0     1.0      1.0   \n",
       "miles   963.0     27.704050     13.378181   10.0    20.0    25.0     32.0   \n",
       "debt    963.0  14109.004154  18273.702481    0.0  1475.0  6236.0  16686.0   \n",
       "income  963.0   6176.047767   3260.670142    0.0  3506.5  6360.0   8649.5   \n",
       "sales   963.0  11689.860852   8986.896921  500.0  3554.0  9130.0  19245.0   \n",
       "\n",
       "            max  \n",
       "age        60.0  \n",
       "gender      1.0  \n",
       "miles      97.0  \n",
       "debt    59770.0  \n",
       "income  11970.0  \n",
       "sales   29926.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando estadísticas básicas con los datos\n",
    "datos_stats = datos.describe()\n",
    "datos_stats = datos_stats.transpose()\n",
    "datos_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las estadísticas anteriores podemos observar que algunas variables tienen grandes rangos y desviaciones, lo cual puede crear problemas durante el ajuste del modelo. Por lo tanto sería buena idea escalar los datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation con optimización de hiperparámetros\n",
    "\n",
    "Por lo general, cuando todavia no sabemos qué modelo es el mejor para nuestros datos, cross validation nos puede ayudar a hacer una comparación más justa entre diferentes modelos. \n",
    "\n",
    "La idea es:\n",
    "1. dividir los datos en train y test\n",
    "2. entrenar múltiples modelos muestreando los datos de entrenamiento. \n",
    "3. Probar el modelo en el test set\n",
    "4. Seleccionar el modelo con nos dio la mejor calificación\n",
    "5. Hacer predicciones con el modelo ganador\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"450px\" height=\"280px\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar la X y Y\n",
    "X=datos.iloc[:,0:5]\n",
    "y=datos.iloc[:,5]\n",
    "\n",
    "#Dividimos los datos en train y test para después hacer el cross validation sólo con los datos del train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Porqué estandarizar los datos después del train test split?**\n",
    "\n",
    "El escalamiento debe realizarse después de dividir los datos en entrenamiento y prueba, y se debe hacer sólo usando los datos de entrenamiento. \n",
    "\n",
    "Esto se debe a que los datos de prueba (test) tienen el papel de datos no vistos por el modelo, por lo que se supone que estos datos no están accesibles en la estapa del entrenamiento. \n",
    "\n",
    "Usar cualquier información proveniente de los datos de prueba antes o durante el entranamiento puede afectar al desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar los folds que vamos a usar para todos los modelos\n",
    "n_folds = 5\n",
    "seed = 7\n",
    "scoring = 'neg_root_mean_squared_error' #usamos el error cuadrático medio como medida de performance\n",
    "kfold = KFold(n_splits=n_folds, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas que vamos a ver\n",
    "scoring = ['r2', 'neg_mean_absolute_error','neg_root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 1: Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train 0.8158013380172221\n",
      "MAE Train 2915.6412524254692\n",
      "RMSE Train 3801.2012383692804\n"
     ]
    }
   ],
   "source": [
    "#Inicializar modelo\n",
    "lm=LinearRegression()\n",
    "\n",
    "#Hacer el cross validation y probar con el train\n",
    "r2_lr= (cross_val_score(lm, X_train,y_train, cv=kfold,  scoring='r2')).mean()\n",
    "mae_lr= -(cross_val_score(lm, X_train,y_train, cv=kfold,  scoring='neg_mean_absolute_error')).mean()\n",
    "mse_lr= (-cross_val_score(lm, X_train,y_train, cv=kfold,  scoring='neg_root_mean_squared_error')).mean()\n",
    "\n",
    "#Performance en el train\n",
    "print(\"R2 train\", r2_lr)\n",
    "print(\"MAE Train\", mae_lr)\n",
    "print(\"RMSE Train\", mse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>2842.934786</td>\n",
       "      <td>3666.939818</td>\n",
       "      <td>0.836061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model          MAE         RMSE        R2\n",
       "0  Linear regression  2842.934786  3666.939818  0.836061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance en el test\n",
    "lm.fit(X_train,y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "mae_lr=mean_absolute_error(y_test,y_pred)\n",
    "rmse_lr=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_lr=r2_score(y_test,y_pred)\n",
    "\n",
    "results_lr = pd.DataFrame([['Linear regression', mae_lr,rmse_lr,r2_lr]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 2: Regresión lineal con regularización Rigde\n",
    "\n",
    "Aquí vamos a usar RidgeCV para encontrar el valor óptimo de $\\lambda$\n",
    "Una vez encontrado ese valor óptimo, creamos el modelo con el valor de $\\lambda$ óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfa: 4.990000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Inicializar modelo de Ridge con cross validation para seleccionar el hiperparámetro de alpha óptimo\n",
    "#Probamos con 3 valores diferentes de alpha a ver cuál es el mejor\n",
    "model = RidgeCV(alphas=np.arange(0.01,5,0.01), cv=kfold, scoring='r2') \n",
    "\n",
    "#Entreno modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#¿Cuál es el alfa óptima?\n",
    "print('alfa: %f' % model.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression Ridge</td>\n",
       "      <td>2844.436399</td>\n",
       "      <td>3666.979515</td>\n",
       "      <td>0.836057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model          MAE         RMSE        R2\n",
       "0  Linear regression Ridge  2844.436399  3666.979515  0.836057"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creo el modelo con el alpha óptima\n",
    "model_ridge_new=Ridge(alpha=4.99)\n",
    "#Entrenar el nuevo modelo con la alpha óptima\n",
    "model_ridge_new.fit(X_train, y_train)\n",
    "\n",
    "#Performance en el test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae_ridge=mean_absolute_error(y_test,y_pred)\n",
    "rmse_ridge=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_ridge=r2_score(y_test,y_pred)\n",
    "\n",
    "results_ridge = pd.DataFrame([['Linear regression Ridge', mae_ridge,rmse_ridge,r2_ridge]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 3: Random Forest\n",
    "\n",
    "Para este modelo vamos a usar cross validation + grid search para encontrar los siguientes hiperparámetros óptimos:\n",
    "- max_depth (profundidad)\n",
    "- min_samples_split (número mínimo de observaciones por split)\n",
    "- n_estimators (número de árboles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=True),\n",
       "             estimator=RandomForestRegressor(min_samples_leaf=2,\n",
       "                                             random_state=0),\n",
       "             param_grid={'max_depth': range(1, 11),\n",
       "                         'min_samples_split': range(10, 60, 10),\n",
       "                         'n_estimators': [100, 300, 500, 800]},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Inicializo modelo\n",
    "model = RandomForestRegressor(min_samples_leaf=2,\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=0)\n",
    "\n",
    "#Grid search para optimizar hiperparámetros\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 11), #profundidad del árbol\n",
    "                                'min_samples_split': range(10, 60, 10), #mínimo numero de observaciones\n",
    "                                'n_estimators': [100, 300, 500, 800] #número de árboles\n",
    "                                }, \n",
    "                  cv=kfold,\n",
    "                  scoring='neg_root_mean_squared_error',\n",
    "                  verbose=0)\n",
    "\n",
    "#Entreno el modelo\n",
    "gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_split': 30, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "#¿cuáles son los hiperparámetros óptimos?\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train 0.892588214294529\n",
      "MAE Train 1965.9151891102506\n",
      "RMSE Train 2897.108349645448\n"
     ]
    }
   ],
   "source": [
    "#crear nuevo modelo usando los parámetros óptimos que obtuvimos\n",
    "new_model_RF = RandomForestRegressor(n_estimators=800,#número de árboles\n",
    "                               criterion='squared_error',\n",
    "                               max_depth=8,\n",
    "                               min_samples_split=30,\n",
    "                               min_samples_leaf=2,\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=0)\n",
    "\n",
    "#Entreno modelo optimizado\n",
    "new_model_RF.fit(X_train, y_train)\n",
    "\n",
    "#Hacer el cross validation y probar con el train\n",
    "r2_rf= (cross_val_score(new_model_RF, X_train,y_train, cv=kfold,  scoring='r2')).mean()\n",
    "mae_rf= -(cross_val_score(new_model_RF, X_train,y_train, cv=kfold,  scoring='neg_mean_absolute_error')).mean()\n",
    "mse_rf= (-cross_val_score(new_model_RF, X_train,y_train, cv=kfold,  scoring='neg_root_mean_squared_error')).mean()\n",
    "\n",
    "#Performance en el train\n",
    "print(\"R2 train\", r2_rf)\n",
    "print(\"MAE Train\", mae_rf)\n",
    "print(\"RMSE Train\", mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1836.106102</td>\n",
       "      <td>2561.377387</td>\n",
       "      <td>0.920012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          MAE         RMSE        R2\n",
       "0  Random Forest  1836.106102  2561.377387  0.920012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance en el test\n",
    "y_pred = new_model_RF.predict(X_test)\n",
    "\n",
    "mae_rf=mean_absolute_error(y_test,y_pred)\n",
    "rmse_rf=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_rf=r2_score(y_test,y_pred)\n",
    "\n",
    "results_rf = pd.DataFrame([['Random Forest', mae_rf,rmse_rf,r2_rf]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol de decisión\n",
    "Para este modelo vamos a usar cross validation + grid search para encontrar los siguientes hiperparámetros óptimos:\n",
    "\n",
    "- max_depth (profundidad)\n",
    "- min_samples_split (número mínimo de observaciones por split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': range(1, 11),\n",
       "                         'min_samples_split': range(10, 60, 10)},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usando cross validation y grid search\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "#Grid search para optimizar hiperparámetros\n",
    "gs = GridSearchCV(tree,\n",
    "                  param_grid = {'max_depth': range(1, 11),\n",
    "                                'min_samples_split': range(10, 60, 10)},\n",
    "                  cv=kfold,\n",
    "                  scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#entreno el modelo\n",
    "gs.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_samples_split': 50}\n"
     ]
    }
   ],
   "source": [
    "#¿cuáles son los hiperparámetros óptimos?\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train 0.8833332245009938\n",
      "MAE Train 2015.0780021702842\n",
      "MSE Train 3019.23963196914\n"
     ]
    }
   ],
   "source": [
    "#crear modelo usando parámetros óptimos\n",
    "new_model_tree = DecisionTreeRegressor(max_depth=7,\n",
    "                                  min_samples_split=50)\n",
    "\n",
    "#Entreno modelo optimizado\n",
    "new_model_tree.fit(X_train, y_train)\n",
    "\n",
    "#Hacer el cross validation y probar con el train\n",
    "r2_tree= (cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='r2')).mean()\n",
    "mae_tree= -(cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='neg_mean_absolute_error')).mean()\n",
    "rmse_tree= (-cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='neg_root_mean_squared_error')).mean()\n",
    "\n",
    "#Performance en el train\n",
    "print(\"R2 train\", r2_tree)\n",
    "print(\"MAE Train\", mae_tree)\n",
    "print(\"MSE Train\", rmse_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1960.984898</td>\n",
       "      <td>2880.276684</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          MAE         RMSE        R2\n",
       "0  Decision Tree  1960.984898  2880.276684  0.898855"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance en el test\n",
    "y_pred = new_model_tree.predict(X_test)\n",
    "\n",
    "mae_tree=mean_absolute_error(y_test,y_pred)\n",
    "rmse_tree=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_tree=r2_score(y_test,y_pred)\n",
    "\n",
    "results_tree = pd.DataFrame([['Decision Tree', mae_tree,rmse_tree,r2_tree]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Máquina de vector soporte (SVR)\n",
    "\n",
    "Para este modelo vamos a usar cross validation + grid search para encontrar los siguientes hiperparámetros óptimos:\n",
    "\n",
    "- Kernel \n",
    "- Hiperparámetros dentro del Kernel\n",
    "- C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=True),\n",
       "             estimator=SVR(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proponer malla para el gridsearch\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "#inicilalizo el modelo\n",
    "model = SVR()\n",
    "\n",
    "#cross validation con gridsearch\n",
    "gs = GridSearchCV(model,\n",
    "                  tuned_parameters, \n",
    "                  cv=kfold,\n",
    "                  scoring='neg_root_mean_squared_error')\n",
    "\n",
    "#entreno el modelo\n",
    "gs.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#cuáles son los hiperparámetros óptimos?\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train 0.8833332245009938\n",
      "MAE Train 2015.0780021702842\n",
      "MSE Train 3019.23963196914\n"
     ]
    }
   ],
   "source": [
    "#crear modelo usando parámetros óptimos\n",
    "new_model_svr = SVR(kernel='linear', C=1000)\n",
    "\n",
    "#Entreno modelo optimizado\n",
    "new_model_svr.fit(X_train, y_train)\n",
    "\n",
    "#Hacer el cross validation y probar con el train\n",
    "r2_svr= (cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='r2')).mean()\n",
    "mae_svr= -(cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='neg_mean_absolute_error')).mean()\n",
    "rmse_svr= (-cross_val_score(new_model_tree, X_train,y_train, cv=kfold,  scoring='neg_root_mean_squared_error')).mean()\n",
    "\n",
    "#Performance en el train\n",
    "print(\"R2 train\", r2_svr)\n",
    "print(\"MAE Train\", mae_svr)\n",
    "print(\"MSE Train\", rmse_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR</td>\n",
       "      <td>2814.094942</td>\n",
       "      <td>3724.912323</td>\n",
       "      <td>0.830836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model          MAE         RMSE        R2\n",
       "0   SVR  2814.094942  3724.912323  0.830836"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance en el test\n",
    "y_pred = new_model_svr.predict(X_test)\n",
    "\n",
    "mae_svr=mean_absolute_error(y_test,y_pred)\n",
    "rmse_svr=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_svr=r2_score(y_test,y_pred)\n",
    "\n",
    "results_svr = pd.DataFrame([['SVR', mae_svr,rmse_svr,r2_svr]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_svr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal\n",
    "\n",
    "Para este modelo vamos a usar Crossvalidation + GridSearch para encontrar los hiperparámetros óptimos:\n",
    "- Tasa de aprendizaje\n",
    "- Momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "\n",
    "#creo función con estructura de la red neuronal\n",
    "def create_model():\n",
    "    # Neural network architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12,activation='tanh',input_dim=5))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(model=create_model, loss='mean_squared_error', optimizer='SGD', epochs=200, batch_size=200, verbose=0)\n",
    "\n",
    "\n",
    "# Definir los parámetros del grid search\n",
    "learn_rate = [0.1, 0.05, 0.01]\n",
    "momentum = [0.8, 0.6, 0.4]\n",
    "param_grid = dict(optimizer__learning_rate=learn_rate, optimizer__momentum=momentum)\n",
    "\n",
    "selection_score = make_scorer(mean_squared_error,greater_is_better=False) #MSE\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=2, scoring=selection_score)\n",
    "\n",
    "#entreno modelo\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.8}\n"
     ]
    }
   ],
   "source": [
    "#¿cuáles son los hiperparámetros óptimos?\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 88657880.0000 - mse: 88657880.0000\n",
      "Epoch 2/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28605468.0000 - mse: 28605468.0000\n",
      "Epoch 3/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23157996.0000 - mse: 23157996.0000\n",
      "Epoch 4/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24333536.0000 - mse: 24333536.0000\n",
      "Epoch 5/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28309036.0000 - mse: 28309036.0000\n",
      "Epoch 6/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22287708.0000 - mse: 22287708.0000\n",
      "Epoch 7/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25174490.0000 - mse: 25174490.0000\n",
      "Epoch 8/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22109554.0000 - mse: 22109554.0000\n",
      "Epoch 9/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22574354.0000 - mse: 22574354.0000\n",
      "Epoch 10/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22867910.0000 - mse: 22867910.0000\n",
      "Epoch 11/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25050048.0000 - mse: 25050048.0000\n",
      "Epoch 12/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23177452.0000 - mse: 23177452.0000\n",
      "Epoch 13/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24182936.0000 - mse: 24182936.0000\n",
      "Epoch 14/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23034482.0000 - mse: 23034482.0000\n",
      "Epoch 15/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22828838.0000 - mse: 22828838.0000\n",
      "Epoch 16/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23474392.0000 - mse: 23474392.0000\n",
      "Epoch 17/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24823042.0000 - mse: 24823042.0000\n",
      "Epoch 18/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25690744.0000 - mse: 25690744.0000\n",
      "Epoch 19/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22877558.0000 - mse: 22877558.0000\n",
      "Epoch 20/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22647848.0000 - mse: 22647848.0000\n",
      "Epoch 21/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 35023736.0000 - mse: 35023736.0000\n",
      "Epoch 22/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24319452.0000 - mse: 24319452.0000\n",
      "Epoch 23/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22966892.0000 - mse: 22966892.0000\n",
      "Epoch 24/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24051816.0000 - mse: 24051816.0000\n",
      "Epoch 25/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23257572.0000 - mse: 23257572.0000\n",
      "Epoch 26/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 32327346.0000 - mse: 32327346.0000\n",
      "Epoch 27/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 27292542.0000 - mse: 27292542.0000\n",
      "Epoch 28/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23822344.0000 - mse: 23822344.0000\n",
      "Epoch 29/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25335704.0000 - mse: 25335704.0000\n",
      "Epoch 30/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23276140.0000 - mse: 23276140.0000\n",
      "Epoch 31/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22642564.0000 - mse: 22642564.0000\n",
      "Epoch 32/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28907124.0000 - mse: 28907124.0000\n",
      "Epoch 33/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23036548.0000 - mse: 23036548.0000\n",
      "Epoch 34/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24713130.0000 - mse: 24713130.0000\n",
      "Epoch 35/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23229774.0000 - mse: 23229774.0000\n",
      "Epoch 36/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26232218.0000 - mse: 26232218.0000\n",
      "Epoch 37/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22837122.0000 - mse: 22837122.0000\n",
      "Epoch 38/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22889892.0000 - mse: 22889892.0000\n",
      "Epoch 39/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25950682.0000 - mse: 25950682.0000\n",
      "Epoch 40/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22349872.0000 - mse: 22349872.0000\n",
      "Epoch 41/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23169170.0000 - mse: 23169170.0000\n",
      "Epoch 42/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23507554.0000 - mse: 23507554.0000\n",
      "Epoch 43/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22480086.0000 - mse: 22480086.0000\n",
      "Epoch 44/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24374200.0000 - mse: 24374200.0000\n",
      "Epoch 45/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22838148.0000 - mse: 22838148.0000\n",
      "Epoch 46/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23522150.0000 - mse: 23522150.0000\n",
      "Epoch 47/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25747162.0000 - mse: 25747162.0000\n",
      "Epoch 48/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23250804.0000 - mse: 23250804.0000\n",
      "Epoch 49/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 35602340.0000 - mse: 35602340.0000\n",
      "Epoch 50/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22442498.0000 - mse: 22442498.0000\n",
      "Epoch 51/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23403650.0000 - mse: 23403650.0000\n",
      "Epoch 52/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25939396.0000 - mse: 25939396.0000\n",
      "Epoch 53/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26300324.0000 - mse: 26300324.0000\n",
      "Epoch 54/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24887316.0000 - mse: 24887316.0000\n",
      "Epoch 55/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24124456.0000 - mse: 24124456.0000\n",
      "Epoch 56/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22873874.0000 - mse: 22873874.0000\n",
      "Epoch 57/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22785286.0000 - mse: 22785286.0000\n",
      "Epoch 58/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26222836.0000 - mse: 26222836.0000\n",
      "Epoch 59/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22177114.0000 - mse: 22177114.0000\n",
      "Epoch 60/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23812138.0000 - mse: 23812138.0000\n",
      "Epoch 61/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21899204.0000 - mse: 21899204.0000\n",
      "Epoch 62/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22545594.0000 - mse: 22545594.0000\n",
      "Epoch 63/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26417158.0000 - mse: 26417158.0000\n",
      "Epoch 64/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26615446.0000 - mse: 26615446.0000\n",
      "Epoch 65/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22749394.0000 - mse: 22749394.0000\n",
      "Epoch 66/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22807230.0000 - mse: 22807230.0000\n",
      "Epoch 67/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27649932.0000 - mse: 27649932.0000\n",
      "Epoch 68/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25116690.0000 - mse: 25116690.0000\n",
      "Epoch 69/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24297880.0000 - mse: 24297880.0000\n",
      "Epoch 70/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26379690.0000 - mse: 26379690.0000\n",
      "Epoch 71/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25364980.0000 - mse: 25364980.0000\n",
      "Epoch 72/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22330856.0000 - mse: 22330856.0000\n",
      "Epoch 73/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23470988.0000 - mse: 23470988.0000\n",
      "Epoch 74/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 27967820.0000 - mse: 27967820.0000\n",
      "Epoch 75/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25047908.0000 - mse: 25047908.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 22282402.0000 - mse: 22282402.0000\n",
      "Epoch 77/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22311722.0000 - mse: 22311722.0000\n",
      "Epoch 78/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22958424.0000 - mse: 22958424.0000\n",
      "Epoch 79/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22857252.0000 - mse: 22857252.0000\n",
      "Epoch 80/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24854318.0000 - mse: 24854318.0000\n",
      "Epoch 81/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23127630.0000 - mse: 23127630.0000\n",
      "Epoch 82/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24870456.0000 - mse: 24870456.0000\n",
      "Epoch 83/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24349680.0000 - mse: 24349680.0000\n",
      "Epoch 84/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23513836.0000 - mse: 23513836.0000\n",
      "Epoch 85/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24783666.0000 - mse: 24783666.0000\n",
      "Epoch 86/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 27072156.0000 - mse: 27072156.0000\n",
      "Epoch 87/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22472414.0000 - mse: 22472414.0000\n",
      "Epoch 88/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24668902.0000 - mse: 24668902.0000\n",
      "Epoch 89/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22540964.0000 - mse: 22540964.0000\n",
      "Epoch 90/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22510108.0000 - mse: 22510108.0000\n",
      "Epoch 91/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23321400.0000 - mse: 23321400.0000\n",
      "Epoch 92/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 32605194.0000 - mse: 32605194.0000\n",
      "Epoch 93/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22457550.0000 - mse: 22457550.0000\n",
      "Epoch 94/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22165458.0000 - mse: 22165458.0000\n",
      "Epoch 95/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23454154.0000 - mse: 23454154.0000\n",
      "Epoch 96/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22286978.0000 - mse: 22286978.0000\n",
      "Epoch 97/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22533774.0000 - mse: 22533774.0000\n",
      "Epoch 98/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24168276.0000 - mse: 24168276.0000\n",
      "Epoch 99/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21888062.0000 - mse: 21888062.0000\n",
      "Epoch 100/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23626862.0000 - mse: 23626862.0000\n",
      "Epoch 101/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23308080.0000 - mse: 23308080.0000\n",
      "Epoch 102/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22887658.0000 - mse: 22887658.0000\n",
      "Epoch 103/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22509218.0000 - mse: 22509218.0000\n",
      "Epoch 104/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24472354.0000 - mse: 24472354.0000\n",
      "Epoch 105/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25490080.0000 - mse: 25490080.0000\n",
      "Epoch 106/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22491000.0000 - mse: 22491000.0000\n",
      "Epoch 107/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22856506.0000 - mse: 22856506.0000\n",
      "Epoch 108/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28931540.0000 - mse: 28931540.0000\n",
      "Epoch 109/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23950056.0000 - mse: 23950056.0000\n",
      "Epoch 110/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22177054.0000 - mse: 22177054.0000\n",
      "Epoch 111/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24915794.0000 - mse: 24915794.0000\n",
      "Epoch 112/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23936950.0000 - mse: 23936950.0000\n",
      "Epoch 113/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22783358.0000 - mse: 22783358.0000\n",
      "Epoch 114/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25172862.0000 - mse: 25172862.0000\n",
      "Epoch 115/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23721796.0000 - mse: 23721796.0000\n",
      "Epoch 116/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24348190.0000 - mse: 24348190.0000\n",
      "Epoch 117/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22623602.0000 - mse: 22623602.0000\n",
      "Epoch 118/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23493024.0000 - mse: 23493024.0000\n",
      "Epoch 119/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28298216.0000 - mse: 28298216.0000\n",
      "Epoch 120/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26592368.0000 - mse: 26592368.0000\n",
      "Epoch 121/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21998840.0000 - mse: 21998840.0000\n",
      "Epoch 122/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25419236.0000 - mse: 25419236.0000\n",
      "Epoch 123/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23003000.0000 - mse: 23003000.0000\n",
      "Epoch 124/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22731666.0000 - mse: 22731666.0000\n",
      "Epoch 125/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22121256.0000 - mse: 22121256.0000\n",
      "Epoch 126/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24729102.0000 - mse: 24729102.0000\n",
      "Epoch 127/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24983502.0000 - mse: 24983502.0000\n",
      "Epoch 128/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23348498.0000 - mse: 23348498.0000\n",
      "Epoch 129/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25445344.0000 - mse: 25445344.0000\n",
      "Epoch 130/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22564488.0000 - mse: 22564488.0000\n",
      "Epoch 131/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 27527064.0000 - mse: 27527064.0000\n",
      "Epoch 132/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23037254.0000 - mse: 23037254.0000\n",
      "Epoch 133/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26360100.0000 - mse: 26360100.0000\n",
      "Epoch 134/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22138070.0000 - mse: 22138070.0000\n",
      "Epoch 135/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24390698.0000 - mse: 24390698.0000\n",
      "Epoch 136/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22788914.0000 - mse: 22788914.0000\n",
      "Epoch 137/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22927012.0000 - mse: 22927012.0000\n",
      "Epoch 138/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25152768.0000 - mse: 25152768.0000\n",
      "Epoch 139/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22991236.0000 - mse: 22991236.0000\n",
      "Epoch 140/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 26785126.0000 - mse: 26785126.0000\n",
      "Epoch 141/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23064012.0000 - mse: 23064012.0000\n",
      "Epoch 142/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28840808.0000 - mse: 28840808.0000\n",
      "Epoch 143/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24417530.0000 - mse: 24417530.0000\n",
      "Epoch 144/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21733722.0000 - mse: 21733722.0000\n",
      "Epoch 145/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23590170.0000 - mse: 23590170.0000\n",
      "Epoch 146/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21992824.0000 - mse: 21992824.0000\n",
      "Epoch 147/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23277148.0000 - mse: 23277148.0000\n",
      "Epoch 148/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25551522.0000 - mse: 25551522.0000\n",
      "Epoch 149/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23506424.0000 - mse: 23506424.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 22150008.0000 - mse: 22150008.0000\n",
      "Epoch 151/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24025070.0000 - mse: 24025070.0000\n",
      "Epoch 152/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 28391928.0000 - mse: 28391928.0000\n",
      "Epoch 153/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22417200.0000 - mse: 22417200.0000\n",
      "Epoch 154/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23818998.0000 - mse: 23818998.0000\n",
      "Epoch 155/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23851348.0000 - mse: 23851348.0000\n",
      "Epoch 156/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22770700.0000 - mse: 22770700.0000\n",
      "Epoch 157/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24324574.0000 - mse: 24324574.0000\n",
      "Epoch 158/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25756900.0000 - mse: 25756900.0000\n",
      "Epoch 159/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24544120.0000 - mse: 24544120.0000\n",
      "Epoch 160/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23040746.0000 - mse: 23040746.0000\n",
      "Epoch 161/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22105916.0000 - mse: 22105916.0000\n",
      "Epoch 162/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23060380.0000 - mse: 23060380.0000\n",
      "Epoch 163/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22867348.0000 - mse: 22867348.0000\n",
      "Epoch 164/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22787018.0000 - mse: 22787018.0000\n",
      "Epoch 165/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23032950.0000 - mse: 23032950.0000\n",
      "Epoch 166/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22560886.0000 - mse: 22560886.0000\n",
      "Epoch 167/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22862674.0000 - mse: 22862674.0000\n",
      "Epoch 168/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22989278.0000 - mse: 22989278.0000\n",
      "Epoch 169/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31427664.0000 - mse: 31427664.0000\n",
      "Epoch 170/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25438384.0000 - mse: 25438384.0000\n",
      "Epoch 171/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23623374.0000 - mse: 23623374.0000\n",
      "Epoch 172/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23001570.0000 - mse: 23001570.0000\n",
      "Epoch 173/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25154860.0000 - mse: 25154860.0000\n",
      "Epoch 174/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23141930.0000 - mse: 23141930.0000\n",
      "Epoch 175/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23847016.0000 - mse: 23847016.0000\n",
      "Epoch 176/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23745522.0000 - mse: 23745522.0000\n",
      "Epoch 177/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25315414.0000 - mse: 25315414.0000\n",
      "Epoch 178/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 32310476.0000 - mse: 32310476.0000\n",
      "Epoch 179/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23012664.0000 - mse: 23012664.0000\n",
      "Epoch 180/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24076524.0000 - mse: 24076524.0000\n",
      "Epoch 181/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21912594.0000 - mse: 21912594.0000\n",
      "Epoch 182/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26126522.0000 - mse: 26126522.0000\n",
      "Epoch 183/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25523018.0000 - mse: 25523018.0000\n",
      "Epoch 184/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24646728.0000 - mse: 24646728.0000\n",
      "Epoch 185/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22913428.0000 - mse: 22913428.0000\n",
      "Epoch 186/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23496164.0000 - mse: 23496164.0000\n",
      "Epoch 187/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22216992.0000 - mse: 22216992.0000\n",
      "Epoch 188/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22712158.0000 - mse: 22712158.0000\n",
      "Epoch 189/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25394620.0000 - mse: 25394620.0000\n",
      "Epoch 190/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25462504.0000 - mse: 25462504.0000\n",
      "Epoch 191/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23679198.0000 - mse: 23679198.0000\n",
      "Epoch 192/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 33536380.0000 - mse: 33536380.0000\n",
      "Epoch 193/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23752390.0000 - mse: 23752390.0000\n",
      "Epoch 194/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23946828.0000 - mse: 23946828.0000\n",
      "Epoch 195/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24120660.0000 - mse: 24120660.0000\n",
      "Epoch 196/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23556258.0000 - mse: 23556258.0000\n",
      "Epoch 197/200\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24517748.0000 - mse: 24517748.0000\n",
      "Epoch 198/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22122792.0000 - mse: 22122792.0000\n",
      "Epoch 199/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23346096.0000 - mse: 23346096.0000\n",
      "Epoch 200/200\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23726852.0000 - mse: 23726852.0000\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 117606864.0000 - mse: 117606864.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33397644.0000 - mse: 33397644.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25164832.0000 - mse: 25164832.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25752144.0000 - mse: 25752144.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25608514.0000 - mse: 25608514.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27341060.0000 - mse: 27341060.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26645888.0000 - mse: 26645888.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30502616.0000 - mse: 30502616.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26349024.0000 - mse: 26349024.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27820354.0000 - mse: 27820354.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25208368.0000 - mse: 25208368.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31995578.0000 - mse: 31995578.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27001726.0000 - mse: 27001726.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24988396.0000 - mse: 24988396.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23142334.0000 - mse: 23142334.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32716648.0000 - mse: 32716648.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25062792.0000 - mse: 25062792.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24548980.0000 - mse: 24548980.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29111236.0000 - mse: 29111236.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25599726.0000 - mse: 25599726.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24199680.0000 - mse: 24199680.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25741066.0000 - mse: 25741066.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25082098.0000 - mse: 25082098.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24471006.0000 - mse: 24471006.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28320366.0000 - mse: 28320366.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29764190.0000 - mse: 29764190.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25464936.0000 - mse: 25464936.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27942992.0000 - mse: 27942992.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27467466.0000 - mse: 27467466.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25542170.0000 - mse: 25542170.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25753400.0000 - mse: 25753400.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24714714.0000 - mse: 24714714.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24870074.0000 - mse: 24870074.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26302658.0000 - mse: 26302658.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28089002.0000 - mse: 28089002.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25081220.0000 - mse: 25081220.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25107398.0000 - mse: 25107398.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25149684.0000 - mse: 25149684.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26668666.0000 - mse: 26668666.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26936226.0000 - mse: 26936226.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24358282.0000 - mse: 24358282.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24891952.0000 - mse: 24891952.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23597926.0000 - mse: 23597926.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23515084.0000 - mse: 23515084.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25371202.0000 - mse: 25371202.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24478238.0000 - mse: 24478238.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28572102.0000 - mse: 28572102.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26980584.0000 - mse: 26980584.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27248264.0000 - mse: 27248264.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24535390.0000 - mse: 24535390.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28107808.0000 - mse: 28107808.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24706148.0000 - mse: 24706148.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24841456.0000 - mse: 24841456.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24446008.0000 - mse: 24446008.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27574406.0000 - mse: 27574406.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26430886.0000 - mse: 26430886.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28201832.0000 - mse: 28201832.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26476060.0000 - mse: 26476060.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26852998.0000 - mse: 26852998.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24084198.0000 - mse: 24084198.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25394854.0000 - mse: 25394854.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26942532.0000 - mse: 26942532.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26800496.0000 - mse: 26800496.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27843732.0000 - mse: 27843732.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26533086.0000 - mse: 26533086.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24758392.0000 - mse: 24758392.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23881530.0000 - mse: 23881530.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24112854.0000 - mse: 24112854.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23709366.0000 - mse: 23709366.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28465948.0000 - mse: 28465948.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25539580.0000 - mse: 25539580.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25322392.0000 - mse: 25322392.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27382912.0000 - mse: 27382912.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26066298.0000 - mse: 26066298.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26765800.0000 - mse: 26765800.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 26128210.0000 - mse: 26128210.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25027112.0000 - mse: 25027112.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25045436.0000 - mse: 25045436.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23887198.0000 - mse: 23887198.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25405824.0000 - mse: 25405824.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29413058.0000 - mse: 29413058.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26723650.0000 - mse: 26723650.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23704706.0000 - mse: 23704706.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28955174.0000 - mse: 28955174.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25530620.0000 - mse: 25530620.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23485648.0000 - mse: 23485648.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28535056.0000 - mse: 28535056.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31691846.0000 - mse: 31691846.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26237988.0000 - mse: 26237988.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25292818.0000 - mse: 25292818.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25451286.0000 - mse: 25451286.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24386668.0000 - mse: 24386668.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27576108.0000 - mse: 27576108.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28301616.0000 - mse: 28301616.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25854980.0000 - mse: 25854980.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28210566.0000 - mse: 28210566.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24167712.0000 - mse: 24167712.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29025846.0000 - mse: 29025846.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27151446.0000 - mse: 27151446.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31496896.0000 - mse: 31496896.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26785964.0000 - mse: 26785964.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26389984.0000 - mse: 26389984.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26342574.0000 - mse: 26342574.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25359716.0000 - mse: 25359716.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27211656.0000 - mse: 27211656.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29964030.0000 - mse: 29964030.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25458622.0000 - mse: 25458622.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28972546.0000 - mse: 28972546.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24388782.0000 - mse: 24388782.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25314594.0000 - mse: 25314594.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26145492.0000 - mse: 26145492.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27153046.0000 - mse: 27153046.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31058650.0000 - mse: 31058650.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25331090.0000 - mse: 25331090.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25640794.0000 - mse: 25640794.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27210582.0000 - mse: 27210582.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31488348.0000 - mse: 31488348.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25010768.0000 - mse: 25010768.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24862074.0000 - mse: 24862074.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24603632.0000 - mse: 24603632.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26926534.0000 - mse: 26926534.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25500716.0000 - mse: 25500716.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28212914.0000 - mse: 28212914.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28428448.0000 - mse: 28428448.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23884382.0000 - mse: 23884382.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25524106.0000 - mse: 25524106.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27223440.0000 - mse: 27223440.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25195064.0000 - mse: 25195064.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25014564.0000 - mse: 25014564.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23667010.0000 - mse: 23667010.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26305420.0000 - mse: 26305420.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26960102.0000 - mse: 26960102.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24393514.0000 - mse: 24393514.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23952082.0000 - mse: 23952082.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25088792.0000 - mse: 25088792.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27825880.0000 - mse: 27825880.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27003576.0000 - mse: 27003576.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28951036.0000 - mse: 28951036.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26705876.0000 - mse: 26705876.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25529424.0000 - mse: 25529424.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24238098.0000 - mse: 24238098.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28040552.0000 - mse: 28040552.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28621036.0000 - mse: 28621036.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24554878.0000 - mse: 24554878.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25728702.0000 - mse: 25728702.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24626044.0000 - mse: 24626044.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24742160.0000 - mse: 24742160.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29693888.0000 - mse: 29693888.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26561202.0000 - mse: 26561202.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 26363184.0000 - mse: 26363184.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26513158.0000 - mse: 26513158.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25239246.0000 - mse: 25239246.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27648984.0000 - mse: 27648984.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25423176.0000 - mse: 25423176.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25594848.0000 - mse: 25594848.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24612466.0000 - mse: 24612466.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26685282.0000 - mse: 26685282.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24712900.0000 - mse: 24712900.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26052438.0000 - mse: 26052438.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26929542.0000 - mse: 26929542.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27473618.0000 - mse: 27473618.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24161316.0000 - mse: 24161316.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26016456.0000 - mse: 26016456.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28264012.0000 - mse: 28264012.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28538172.0000 - mse: 28538172.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26040170.0000 - mse: 26040170.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27671460.0000 - mse: 27671460.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29292494.0000 - mse: 29292494.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26269694.0000 - mse: 26269694.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24652114.0000 - mse: 24652114.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29394774.0000 - mse: 29394774.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27012754.0000 - mse: 27012754.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27028314.0000 - mse: 27028314.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26432418.0000 - mse: 26432418.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25223684.0000 - mse: 25223684.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24361590.0000 - mse: 24361590.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27005554.0000 - mse: 27005554.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25375484.0000 - mse: 25375484.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26571628.0000 - mse: 26571628.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24807138.0000 - mse: 24807138.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28749406.0000 - mse: 28749406.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27318952.0000 - mse: 27318952.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26065914.0000 - mse: 26065914.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25997348.0000 - mse: 25997348.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24880058.0000 - mse: 24880058.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27089510.0000 - mse: 27089510.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25689414.0000 - mse: 25689414.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25734460.0000 - mse: 25734460.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24512190.0000 - mse: 24512190.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26037284.0000 - mse: 26037284.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26787404.0000 - mse: 26787404.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24965474.0000 - mse: 24965474.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27586228.0000 - mse: 27586228.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 30349700.0000 - mse: 30349700.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24543892.0000 - mse: 24543892.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24780782.0000 - mse: 24780782.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23845794.0000 - mse: 23845794.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27745020.0000 - mse: 27745020.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24628440.0000 - mse: 24628440.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25865210.0000 - mse: 25865210.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 83903824.0000 - mse: 83903824.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28231626.0000 - mse: 28231626.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26484238.0000 - mse: 26484238.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26184912.0000 - mse: 26184912.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25723312.0000 - mse: 25723312.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24955694.0000 - mse: 24955694.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25752668.0000 - mse: 25752668.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25538324.0000 - mse: 25538324.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26384182.0000 - mse: 26384182.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24587584.0000 - mse: 24587584.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25233338.0000 - mse: 25233338.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26020482.0000 - mse: 26020482.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25576120.0000 - mse: 25576120.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26634464.0000 - mse: 26634464.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26870608.0000 - mse: 26870608.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24741692.0000 - mse: 24741692.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26331948.0000 - mse: 26331948.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27550260.0000 - mse: 27550260.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27181938.0000 - mse: 27181938.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26289770.0000 - mse: 26289770.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26453496.0000 - mse: 26453496.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26260386.0000 - mse: 26260386.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25434372.0000 - mse: 25434372.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26224154.0000 - mse: 26224154.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26014036.0000 - mse: 26014036.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26605556.0000 - mse: 26605556.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25656042.0000 - mse: 25656042.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26935790.0000 - mse: 26935790.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24699586.0000 - mse: 24699586.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26863174.0000 - mse: 26863174.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25946214.0000 - mse: 25946214.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25777006.0000 - mse: 25777006.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26044336.0000 - mse: 26044336.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25666940.0000 - mse: 25666940.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25718212.0000 - mse: 25718212.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27232276.0000 - mse: 27232276.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26676658.0000 - mse: 26676658.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25656002.0000 - mse: 25656002.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25887144.0000 - mse: 25887144.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26205240.0000 - mse: 26205240.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26218458.0000 - mse: 26218458.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25600214.0000 - mse: 25600214.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26644656.0000 - mse: 26644656.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26580708.0000 - mse: 26580708.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25737058.0000 - mse: 25737058.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25700136.0000 - mse: 25700136.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24894222.0000 - mse: 24894222.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25891364.0000 - mse: 25891364.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27344570.0000 - mse: 27344570.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25291692.0000 - mse: 25291692.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25438122.0000 - mse: 25438122.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24855452.0000 - mse: 24855452.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25961986.0000 - mse: 25961986.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26119212.0000 - mse: 26119212.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25350768.0000 - mse: 25350768.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25891636.0000 - mse: 25891636.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26082030.0000 - mse: 26082030.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25823516.0000 - mse: 25823516.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25522006.0000 - mse: 25522006.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26159304.0000 - mse: 26159304.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27661420.0000 - mse: 27661420.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25215994.0000 - mse: 25215994.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25705788.0000 - mse: 25705788.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26802550.0000 - mse: 26802550.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26604948.0000 - mse: 26604948.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27518132.0000 - mse: 27518132.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26077620.0000 - mse: 26077620.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25968954.0000 - mse: 25968954.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24879390.0000 - mse: 24879390.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25332770.0000 - mse: 25332770.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28980298.0000 - mse: 28980298.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26705172.0000 - mse: 26705172.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26670526.0000 - mse: 26670526.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26380520.0000 - mse: 26380520.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26015358.0000 - mse: 26015358.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 26047884.0000 - mse: 26047884.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25718454.0000 - mse: 25718454.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26722726.0000 - mse: 26722726.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27026772.0000 - mse: 27026772.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27472362.0000 - mse: 27472362.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26007062.0000 - mse: 26007062.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26868606.0000 - mse: 26868606.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24560228.0000 - mse: 24560228.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25012466.0000 - mse: 25012466.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25790454.0000 - mse: 25790454.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25825810.0000 - mse: 25825810.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26234010.0000 - mse: 26234010.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26392412.0000 - mse: 26392412.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25266676.0000 - mse: 25266676.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25060470.0000 - mse: 25060470.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26233016.0000 - mse: 26233016.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26687626.0000 - mse: 26687626.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24765390.0000 - mse: 24765390.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25634434.0000 - mse: 25634434.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25443894.0000 - mse: 25443894.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26190564.0000 - mse: 26190564.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26036926.0000 - mse: 26036926.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26111336.0000 - mse: 26111336.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26064520.0000 - mse: 26064520.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26305138.0000 - mse: 26305138.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25925548.0000 - mse: 25925548.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26033706.0000 - mse: 26033706.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25578542.0000 - mse: 25578542.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24712454.0000 - mse: 24712454.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25826996.0000 - mse: 25826996.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28054644.0000 - mse: 28054644.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26001198.0000 - mse: 26001198.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25814530.0000 - mse: 25814530.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25950510.0000 - mse: 25950510.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25747076.0000 - mse: 25747076.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25747712.0000 - mse: 25747712.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25917042.0000 - mse: 25917042.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26536304.0000 - mse: 26536304.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26114476.0000 - mse: 26114476.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25908750.0000 - mse: 25908750.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25396952.0000 - mse: 25396952.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25711938.0000 - mse: 25711938.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26138022.0000 - mse: 26138022.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26365754.0000 - mse: 26365754.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26463786.0000 - mse: 26463786.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26537162.0000 - mse: 26537162.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25596734.0000 - mse: 25596734.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27897646.0000 - mse: 27897646.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26238258.0000 - mse: 26238258.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25045260.0000 - mse: 25045260.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26242280.0000 - mse: 26242280.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25525964.0000 - mse: 25525964.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26379958.0000 - mse: 26379958.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28099248.0000 - mse: 28099248.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26341432.0000 - mse: 26341432.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27131570.0000 - mse: 27131570.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 30990374.0000 - mse: 30990374.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26380732.0000 - mse: 26380732.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26639660.0000 - mse: 26639660.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26924444.0000 - mse: 26924444.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26477534.0000 - mse: 26477534.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26058348.0000 - mse: 26058348.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28256634.0000 - mse: 28256634.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25767538.0000 - mse: 25767538.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24469770.0000 - mse: 24469770.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27986584.0000 - mse: 27986584.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26672356.0000 - mse: 26672356.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25909598.0000 - mse: 25909598.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27167120.0000 - mse: 27167120.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25947968.0000 - mse: 25947968.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25923500.0000 - mse: 25923500.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25262896.0000 - mse: 25262896.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25196632.0000 - mse: 25196632.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25212658.0000 - mse: 25212658.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 25342570.0000 - mse: 25342570.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25593988.0000 - mse: 25593988.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25248388.0000 - mse: 25248388.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25449730.0000 - mse: 25449730.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26235948.0000 - mse: 26235948.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25309568.0000 - mse: 25309568.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27848514.0000 - mse: 27848514.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25654502.0000 - mse: 25654502.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26906406.0000 - mse: 26906406.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25918454.0000 - mse: 25918454.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25418160.0000 - mse: 25418160.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25123640.0000 - mse: 25123640.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24589028.0000 - mse: 24589028.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25002804.0000 - mse: 25002804.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24633592.0000 - mse: 24633592.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25026606.0000 - mse: 25026606.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25242486.0000 - mse: 25242486.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26084812.0000 - mse: 26084812.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25439248.0000 - mse: 25439248.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26360178.0000 - mse: 26360178.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24994122.0000 - mse: 24994122.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26558730.0000 - mse: 26558730.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26753326.0000 - mse: 26753326.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25326942.0000 - mse: 25326942.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25725134.0000 - mse: 25725134.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26761956.0000 - mse: 26761956.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25439826.0000 - mse: 25439826.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26885366.0000 - mse: 26885366.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24897934.0000 - mse: 24897934.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27330320.0000 - mse: 27330320.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25529660.0000 - mse: 25529660.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26420508.0000 - mse: 26420508.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25675908.0000 - mse: 25675908.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25927280.0000 - mse: 25927280.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25658298.0000 - mse: 25658298.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24888978.0000 - mse: 24888978.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26266474.0000 - mse: 26266474.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26450234.0000 - mse: 26450234.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25180688.0000 - mse: 25180688.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25518518.0000 - mse: 25518518.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25582172.0000 - mse: 25582172.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26281416.0000 - mse: 26281416.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26418206.0000 - mse: 26418206.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26990868.0000 - mse: 26990868.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24783860.0000 - mse: 24783860.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26713230.0000 - mse: 26713230.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26557800.0000 - mse: 26557800.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26784590.0000 - mse: 26784590.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26171256.0000 - mse: 26171256.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26407574.0000 - mse: 26407574.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25549090.0000 - mse: 25549090.0000\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 2ms/step - loss: 69724928.0000 - mse: 69724928.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31639274.0000 - mse: 31639274.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31318848.0000 - mse: 31318848.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29207022.0000 - mse: 29207022.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29837130.0000 - mse: 29837130.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30740242.0000 - mse: 30740242.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28807920.0000 - mse: 28807920.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28610928.0000 - mse: 28610928.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28142816.0000 - mse: 28142816.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29190910.0000 - mse: 29190910.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28455690.0000 - mse: 28455690.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28251946.0000 - mse: 28251946.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28546814.0000 - mse: 28546814.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28032018.0000 - mse: 28032018.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28494536.0000 - mse: 28494536.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29705140.0000 - mse: 29705140.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27774784.0000 - mse: 27774784.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28118148.0000 - mse: 28118148.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27200372.0000 - mse: 27200372.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27936828.0000 - mse: 27936828.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27703148.0000 - mse: 27703148.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29344150.0000 - mse: 29344150.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27444294.0000 - mse: 27444294.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28591354.0000 - mse: 28591354.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29031274.0000 - mse: 29031274.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29786130.0000 - mse: 29786130.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28118582.0000 - mse: 28118582.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26631340.0000 - mse: 26631340.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29202772.0000 - mse: 29202772.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28396098.0000 - mse: 28396098.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30450112.0000 - mse: 30450112.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28677306.0000 - mse: 28677306.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27979430.0000 - mse: 27979430.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27299880.0000 - mse: 27299880.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28280474.0000 - mse: 28280474.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28699924.0000 - mse: 28699924.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29229334.0000 - mse: 29229334.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29385144.0000 - mse: 29385144.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27951412.0000 - mse: 27951412.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31819604.0000 - mse: 31819604.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28253510.0000 - mse: 28253510.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28298318.0000 - mse: 28298318.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27897008.0000 - mse: 27897008.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27478256.0000 - mse: 27478256.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28857768.0000 - mse: 28857768.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28201142.0000 - mse: 28201142.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28381768.0000 - mse: 28381768.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27180276.0000 - mse: 27180276.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27510626.0000 - mse: 27510626.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27462286.0000 - mse: 27462286.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28355534.0000 - mse: 28355534.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28175802.0000 - mse: 28175802.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27209414.0000 - mse: 27209414.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27239032.0000 - mse: 27239032.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26922608.0000 - mse: 26922608.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28317050.0000 - mse: 28317050.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29538406.0000 - mse: 29538406.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28622620.0000 - mse: 28622620.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27161518.0000 - mse: 27161518.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27620408.0000 - mse: 27620408.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27508032.0000 - mse: 27508032.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29480538.0000 - mse: 29480538.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27877322.0000 - mse: 27877322.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27386628.0000 - mse: 27386628.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28387080.0000 - mse: 28387080.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27871578.0000 - mse: 27871578.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27633328.0000 - mse: 27633328.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27748496.0000 - mse: 27748496.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27795718.0000 - mse: 27795718.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27938098.0000 - mse: 27938098.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27623946.0000 - mse: 27623946.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27484674.0000 - mse: 27484674.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29299516.0000 - mse: 29299516.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28227984.0000 - mse: 28227984.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27627860.0000 - mse: 27627860.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 27844058.0000 - mse: 27844058.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27671490.0000 - mse: 27671490.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 29812668.0000 - mse: 29812668.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26579868.0000 - mse: 26579868.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27240672.0000 - mse: 27240672.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27664540.0000 - mse: 27664540.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28496926.0000 - mse: 28496926.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27256712.0000 - mse: 27256712.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28234756.0000 - mse: 28234756.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26980948.0000 - mse: 26980948.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27780596.0000 - mse: 27780596.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27970042.0000 - mse: 27970042.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26268080.0000 - mse: 26268080.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27967796.0000 - mse: 27967796.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30182798.0000 - mse: 30182798.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27704462.0000 - mse: 27704462.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27049254.0000 - mse: 27049254.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26720246.0000 - mse: 26720246.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26978782.0000 - mse: 26978782.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27884930.0000 - mse: 27884930.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28633698.0000 - mse: 28633698.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28234262.0000 - mse: 28234262.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28266586.0000 - mse: 28266586.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29626208.0000 - mse: 29626208.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27483292.0000 - mse: 27483292.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28446376.0000 - mse: 28446376.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28752752.0000 - mse: 28752752.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28218408.0000 - mse: 28218408.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26771950.0000 - mse: 26771950.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28576978.0000 - mse: 28576978.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27590804.0000 - mse: 27590804.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27461162.0000 - mse: 27461162.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28461806.0000 - mse: 28461806.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28481834.0000 - mse: 28481834.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27007102.0000 - mse: 27007102.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27691734.0000 - mse: 27691734.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27405432.0000 - mse: 27405432.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27796360.0000 - mse: 27796360.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26883776.0000 - mse: 26883776.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28648550.0000 - mse: 28648550.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27615398.0000 - mse: 27615398.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28382648.0000 - mse: 28382648.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29652828.0000 - mse: 29652828.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26871240.0000 - mse: 26871240.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27298294.0000 - mse: 27298294.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27481996.0000 - mse: 27481996.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27306600.0000 - mse: 27306600.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28567000.0000 - mse: 28567000.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28035304.0000 - mse: 28035304.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27762538.0000 - mse: 27762538.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29736412.0000 - mse: 29736412.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27172076.0000 - mse: 27172076.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29336048.0000 - mse: 29336048.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27019440.0000 - mse: 27019440.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28657296.0000 - mse: 28657296.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26224040.0000 - mse: 26224040.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27140386.0000 - mse: 27140386.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28708802.0000 - mse: 28708802.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27591132.0000 - mse: 27591132.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 28539502.0000 - mse: 28539502.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30671530.0000 - mse: 30671530.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27703668.0000 - mse: 27703668.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29254470.0000 - mse: 29254470.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28042606.0000 - mse: 28042606.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27443160.0000 - mse: 27443160.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28185948.0000 - mse: 28185948.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27490248.0000 - mse: 27490248.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27409732.0000 - mse: 27409732.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27449246.0000 - mse: 27449246.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27964128.0000 - mse: 27964128.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28228850.0000 - mse: 28228850.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28969188.0000 - mse: 28969188.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27680412.0000 - mse: 27680412.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28521884.0000 - mse: 28521884.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 28307808.0000 - mse: 28307808.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27165632.0000 - mse: 27165632.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29436716.0000 - mse: 29436716.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26199142.0000 - mse: 26199142.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29009748.0000 - mse: 29009748.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28573940.0000 - mse: 28573940.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30181382.0000 - mse: 30181382.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27584752.0000 - mse: 27584752.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28111364.0000 - mse: 28111364.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27686572.0000 - mse: 27686572.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29353150.0000 - mse: 29353150.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28766580.0000 - mse: 28766580.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28097438.0000 - mse: 28097438.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28825810.0000 - mse: 28825810.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27979050.0000 - mse: 27979050.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27571626.0000 - mse: 27571626.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27573564.0000 - mse: 27573564.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26666536.0000 - mse: 26666536.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27002140.0000 - mse: 27002140.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29432106.0000 - mse: 29432106.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27848230.0000 - mse: 27848230.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28179348.0000 - mse: 28179348.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26580014.0000 - mse: 26580014.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29036420.0000 - mse: 29036420.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28140758.0000 - mse: 28140758.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26465110.0000 - mse: 26465110.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26983898.0000 - mse: 26983898.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27052300.0000 - mse: 27052300.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28019632.0000 - mse: 28019632.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27740476.0000 - mse: 27740476.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27922148.0000 - mse: 27922148.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28024444.0000 - mse: 28024444.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27890470.0000 - mse: 27890470.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29286502.0000 - mse: 29286502.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27232504.0000 - mse: 27232504.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29529048.0000 - mse: 29529048.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27197208.0000 - mse: 27197208.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28643988.0000 - mse: 28643988.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27761872.0000 - mse: 27761872.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27308850.0000 - mse: 27308850.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27076628.0000 - mse: 27076628.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26718220.0000 - mse: 26718220.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28723496.0000 - mse: 28723496.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29560576.0000 - mse: 29560576.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28233922.0000 - mse: 28233922.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26448488.0000 - mse: 26448488.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27877188.0000 - mse: 27877188.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27917240.0000 - mse: 27917240.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28372224.0000 - mse: 28372224.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28318920.0000 - mse: 28318920.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29133076.0000 - mse: 29133076.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 75290104.0000 - mse: 75290104.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37563620.0000 - mse: 37563620.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34782108.0000 - mse: 34782108.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35734076.0000 - mse: 35734076.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35650896.0000 - mse: 35650896.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35286080.0000 - mse: 35286080.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33449706.0000 - mse: 33449706.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34575384.0000 - mse: 34575384.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33274278.0000 - mse: 33274278.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32035120.0000 - mse: 32035120.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33311264.0000 - mse: 33311264.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34887112.0000 - mse: 34887112.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34396744.0000 - mse: 34396744.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32891192.0000 - mse: 32891192.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34637124.0000 - mse: 34637124.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 31422014.0000 - mse: 31422014.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33975416.0000 - mse: 33975416.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35367508.0000 - mse: 35367508.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39991184.0000 - mse: 39991184.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32656660.0000 - mse: 32656660.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34474432.0000 - mse: 34474432.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33105566.0000 - mse: 33105566.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36435812.0000 - mse: 36435812.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35729564.0000 - mse: 35729564.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33887508.0000 - mse: 33887508.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39189104.0000 - mse: 39189104.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35597800.0000 - mse: 35597800.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36385888.0000 - mse: 36385888.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33595836.0000 - mse: 33595836.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37538128.0000 - mse: 37538128.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33799612.0000 - mse: 33799612.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34770560.0000 - mse: 34770560.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33674612.0000 - mse: 33674612.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35286432.0000 - mse: 35286432.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33748828.0000 - mse: 33748828.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32149014.0000 - mse: 32149014.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33838064.0000 - mse: 33838064.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35691584.0000 - mse: 35691584.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33161162.0000 - mse: 33161162.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38786544.0000 - mse: 38786544.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33644380.0000 - mse: 33644380.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34001344.0000 - mse: 34001344.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34590148.0000 - mse: 34590148.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35549540.0000 - mse: 35549540.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33834456.0000 - mse: 33834456.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34221552.0000 - mse: 34221552.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35386744.0000 - mse: 35386744.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35272928.0000 - mse: 35272928.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33237338.0000 - mse: 33237338.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35462364.0000 - mse: 35462364.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35639108.0000 - mse: 35639108.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33629716.0000 - mse: 33629716.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35143500.0000 - mse: 35143500.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32284174.0000 - mse: 32284174.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32815872.0000 - mse: 32815872.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33842024.0000 - mse: 33842024.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32782644.0000 - mse: 32782644.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36162108.0000 - mse: 36162108.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33042626.0000 - mse: 33042626.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32932774.0000 - mse: 32932774.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38358412.0000 - mse: 38358412.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34025996.0000 - mse: 34025996.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35444096.0000 - mse: 35444096.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34994260.0000 - mse: 34994260.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37038844.0000 - mse: 37038844.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34757444.0000 - mse: 34757444.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35501420.0000 - mse: 35501420.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37217164.0000 - mse: 37217164.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33219540.0000 - mse: 33219540.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33612548.0000 - mse: 33612548.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36206076.0000 - mse: 36206076.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34321120.0000 - mse: 34321120.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34968304.0000 - mse: 34968304.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32766316.0000 - mse: 32766316.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35089656.0000 - mse: 35089656.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 34258412.0000 - mse: 34258412.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33985016.0000 - mse: 33985016.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34175612.0000 - mse: 34175612.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36549600.0000 - mse: 36549600.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35726944.0000 - mse: 35726944.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34975280.0000 - mse: 34975280.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34721020.0000 - mse: 34721020.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34875368.0000 - mse: 34875368.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38864172.0000 - mse: 38864172.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35341748.0000 - mse: 35341748.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33831392.0000 - mse: 33831392.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37043596.0000 - mse: 37043596.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38152864.0000 - mse: 38152864.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36188996.0000 - mse: 36188996.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36732144.0000 - mse: 36732144.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34867484.0000 - mse: 34867484.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 34349676.0000 - mse: 34349676.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32607868.0000 - mse: 32607868.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33616776.0000 - mse: 33616776.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33093936.0000 - mse: 33093936.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33557200.0000 - mse: 33557200.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31956856.0000 - mse: 31956856.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33556192.0000 - mse: 33556192.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35607260.0000 - mse: 35607260.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34772908.0000 - mse: 34772908.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36077352.0000 - mse: 36077352.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35662396.0000 - mse: 35662396.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32667606.0000 - mse: 32667606.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32179562.0000 - mse: 32179562.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32075488.0000 - mse: 32075488.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37736764.0000 - mse: 37736764.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34667968.0000 - mse: 34667968.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34283184.0000 - mse: 34283184.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43154200.0000 - mse: 43154200.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33511314.0000 - mse: 33511314.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33805552.0000 - mse: 33805552.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34867856.0000 - mse: 34867856.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35427328.0000 - mse: 35427328.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34768312.0000 - mse: 34768312.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33405088.0000 - mse: 33405088.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34681576.0000 - mse: 34681576.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34446744.0000 - mse: 34446744.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35947032.0000 - mse: 35947032.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34530084.0000 - mse: 34530084.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37432108.0000 - mse: 37432108.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32495050.0000 - mse: 32495050.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33396302.0000 - mse: 33396302.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34710736.0000 - mse: 34710736.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32979890.0000 - mse: 32979890.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33080790.0000 - mse: 33080790.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36566208.0000 - mse: 36566208.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32621972.0000 - mse: 32621972.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36122660.0000 - mse: 36122660.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34224924.0000 - mse: 34224924.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33025322.0000 - mse: 33025322.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32773102.0000 - mse: 32773102.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32607994.0000 - mse: 32607994.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34959944.0000 - mse: 34959944.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36440176.0000 - mse: 36440176.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36501228.0000 - mse: 36501228.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35396004.0000 - mse: 35396004.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34950932.0000 - mse: 34950932.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38324876.0000 - mse: 38324876.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35779936.0000 - mse: 35779936.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33013984.0000 - mse: 33013984.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34189944.0000 - mse: 34189944.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34775144.0000 - mse: 34775144.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38996172.0000 - mse: 38996172.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34670176.0000 - mse: 34670176.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36028444.0000 - mse: 36028444.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34200224.0000 - mse: 34200224.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33093354.0000 - mse: 33093354.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33802568.0000 - mse: 33802568.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32101188.0000 - mse: 32101188.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 35487776.0000 - mse: 35487776.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33294354.0000 - mse: 33294354.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35844068.0000 - mse: 35844068.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32541702.0000 - mse: 32541702.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 38062344.0000 - mse: 38062344.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33586936.0000 - mse: 33586936.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41643752.0000 - mse: 41643752.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 44602704.0000 - mse: 44602704.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 36230236.0000 - mse: 36230236.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 35918204.0000 - mse: 35918204.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34386184.0000 - mse: 34386184.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31906236.0000 - mse: 31906236.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36151016.0000 - mse: 36151016.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33113208.0000 - mse: 33113208.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36110840.0000 - mse: 36110840.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33840004.0000 - mse: 33840004.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34625408.0000 - mse: 34625408.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33425302.0000 - mse: 33425302.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36517776.0000 - mse: 36517776.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35600548.0000 - mse: 35600548.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34866252.0000 - mse: 34866252.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37184524.0000 - mse: 37184524.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32661554.0000 - mse: 32661554.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32865814.0000 - mse: 32865814.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34743932.0000 - mse: 34743932.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 32208998.0000 - mse: 32208998.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36968988.0000 - mse: 36968988.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33214110.0000 - mse: 33214110.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33963616.0000 - mse: 33963616.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37212848.0000 - mse: 37212848.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36328996.0000 - mse: 36328996.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31824488.0000 - mse: 31824488.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38225892.0000 - mse: 38225892.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37252988.0000 - mse: 37252988.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32229030.0000 - mse: 32229030.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35418396.0000 - mse: 35418396.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35067560.0000 - mse: 35067560.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35231064.0000 - mse: 35231064.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33433474.0000 - mse: 33433474.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37140680.0000 - mse: 37140680.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33032804.0000 - mse: 33032804.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33864356.0000 - mse: 33864356.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35512820.0000 - mse: 35512820.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33401444.0000 - mse: 33401444.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33077844.0000 - mse: 33077844.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34328256.0000 - mse: 34328256.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34608028.0000 - mse: 34608028.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35675548.0000 - mse: 35675548.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35750088.0000 - mse: 35750088.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33471726.0000 - mse: 33471726.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 34568396.0000 - mse: 34568396.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 53901496.0000 - mse: 53901496.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22075178.0000 - mse: 22075178.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23542270.0000 - mse: 23542270.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24324744.0000 - mse: 24324744.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22425988.0000 - mse: 22425988.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22526476.0000 - mse: 22526476.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22884922.0000 - mse: 22884922.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21840002.0000 - mse: 21840002.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22610212.0000 - mse: 22610212.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22235230.0000 - mse: 22235230.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23060982.0000 - mse: 23060982.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23105626.0000 - mse: 23105626.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21837376.0000 - mse: 21837376.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22429978.0000 - mse: 22429978.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22252354.0000 - mse: 22252354.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22064128.0000 - mse: 22064128.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21630872.0000 - mse: 21630872.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23418752.0000 - mse: 23418752.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22398432.0000 - mse: 22398432.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22563000.0000 - mse: 22563000.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23216284.0000 - mse: 23216284.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22745452.0000 - mse: 22745452.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22258884.0000 - mse: 22258884.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21676438.0000 - mse: 21676438.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 985us/step - loss: 22871454.0000 - mse: 22871454.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 998us/step - loss: 22599988.0000 - mse: 22599988.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23010344.0000 - mse: 23010344.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22351902.0000 - mse: 22351902.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22367290.0000 - mse: 22367290.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22423464.0000 - mse: 22423464.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22104990.0000 - mse: 22104990.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23193956.0000 - mse: 23193956.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21429294.0000 - mse: 21429294.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 937us/step - loss: 22385726.0000 - mse: 22385726.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22029762.0000 - mse: 22029762.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 907us/step - loss: 23163678.0000 - mse: 23163678.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22307976.0000 - mse: 22307976.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22295674.0000 - mse: 22295674.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24513676.0000 - mse: 24513676.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23675280.0000 - mse: 23675280.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22175938.0000 - mse: 22175938.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22202196.0000 - mse: 22202196.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22020634.0000 - mse: 22020634.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22883228.0000 - mse: 22883228.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22823106.0000 - mse: 22823106.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22053420.0000 - mse: 22053420.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23070088.0000 - mse: 23070088.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23614526.0000 - mse: 23614526.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22503720.0000 - mse: 22503720.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24231320.0000 - mse: 24231320.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23596300.0000 - mse: 23596300.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22206976.0000 - mse: 22206976.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24560280.0000 - mse: 24560280.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23416858.0000 - mse: 23416858.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23306610.0000 - mse: 23306610.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22141268.0000 - mse: 22141268.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23670332.0000 - mse: 23670332.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24133666.0000 - mse: 24133666.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21890316.0000 - mse: 21890316.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23271434.0000 - mse: 23271434.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21695106.0000 - mse: 21695106.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23491334.0000 - mse: 23491334.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21848664.0000 - mse: 21848664.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24350544.0000 - mse: 24350544.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23130414.0000 - mse: 23130414.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21684806.0000 - mse: 21684806.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22214488.0000 - mse: 22214488.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22397936.0000 - mse: 22397936.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21782100.0000 - mse: 21782100.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23315688.0000 - mse: 23315688.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22824352.0000 - mse: 22824352.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22276446.0000 - mse: 22276446.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21975992.0000 - mse: 21975992.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23574738.0000 - mse: 23574738.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22221080.0000 - mse: 22221080.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 23317502.0000 - mse: 23317502.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22383494.0000 - mse: 22383494.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22942636.0000 - mse: 22942636.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22274706.0000 - mse: 22274706.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22387110.0000 - mse: 22387110.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21860742.0000 - mse: 21860742.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21748356.0000 - mse: 21748356.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21909322.0000 - mse: 21909322.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23068058.0000 - mse: 23068058.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22055052.0000 - mse: 22055052.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21412996.0000 - mse: 21412996.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22637120.0000 - mse: 22637120.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23055896.0000 - mse: 23055896.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24401134.0000 - mse: 24401134.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22310480.0000 - mse: 22310480.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23552194.0000 - mse: 23552194.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25192944.0000 - mse: 25192944.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22267392.0000 - mse: 22267392.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23077142.0000 - mse: 23077142.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22615748.0000 - mse: 22615748.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22455862.0000 - mse: 22455862.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22047816.0000 - mse: 22047816.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24209926.0000 - mse: 24209926.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21833518.0000 - mse: 21833518.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21922758.0000 - mse: 21922758.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24257420.0000 - mse: 24257420.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23444780.0000 - mse: 23444780.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22115254.0000 - mse: 22115254.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22108330.0000 - mse: 22108330.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22661720.0000 - mse: 22661720.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21607850.0000 - mse: 21607850.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23561952.0000 - mse: 23561952.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23611782.0000 - mse: 23611782.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22430190.0000 - mse: 22430190.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21558956.0000 - mse: 21558956.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23807524.0000 - mse: 23807524.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21758604.0000 - mse: 21758604.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22513828.0000 - mse: 22513828.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22668834.0000 - mse: 22668834.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23296294.0000 - mse: 23296294.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23748234.0000 - mse: 23748234.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24002628.0000 - mse: 24002628.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22491112.0000 - mse: 22491112.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22338388.0000 - mse: 22338388.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22300492.0000 - mse: 22300492.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24048726.0000 - mse: 24048726.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23677984.0000 - mse: 23677984.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22579058.0000 - mse: 22579058.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23200676.0000 - mse: 23200676.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23017428.0000 - mse: 23017428.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23066168.0000 - mse: 23066168.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21848124.0000 - mse: 21848124.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22001006.0000 - mse: 22001006.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23002984.0000 - mse: 23002984.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22501832.0000 - mse: 22501832.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22596768.0000 - mse: 22596768.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22197948.0000 - mse: 22197948.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21705080.0000 - mse: 21705080.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22019512.0000 - mse: 22019512.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22353478.0000 - mse: 22353478.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23071420.0000 - mse: 23071420.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22465226.0000 - mse: 22465226.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24579576.0000 - mse: 24579576.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23713842.0000 - mse: 23713842.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23964398.0000 - mse: 23964398.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22196884.0000 - mse: 22196884.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21776488.0000 - mse: 21776488.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21548964.0000 - mse: 21548964.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24816398.0000 - mse: 24816398.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21506906.0000 - mse: 21506906.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22250990.0000 - mse: 22250990.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21636074.0000 - mse: 21636074.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21715028.0000 - mse: 21715028.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22097174.0000 - mse: 22097174.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 22485216.0000 - mse: 22485216.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23616288.0000 - mse: 23616288.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23857584.0000 - mse: 23857584.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21921436.0000 - mse: 21921436.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23379584.0000 - mse: 23379584.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23928884.0000 - mse: 23928884.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23173470.0000 - mse: 23173470.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21468742.0000 - mse: 21468742.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23983754.0000 - mse: 23983754.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24120302.0000 - mse: 24120302.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22833572.0000 - mse: 22833572.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23218432.0000 - mse: 23218432.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22699110.0000 - mse: 22699110.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22504950.0000 - mse: 22504950.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23557596.0000 - mse: 23557596.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22681346.0000 - mse: 22681346.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22424372.0000 - mse: 22424372.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21801710.0000 - mse: 21801710.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23432446.0000 - mse: 23432446.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23819714.0000 - mse: 23819714.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22451598.0000 - mse: 22451598.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24086416.0000 - mse: 24086416.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22581748.0000 - mse: 22581748.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22518156.0000 - mse: 22518156.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22058996.0000 - mse: 22058996.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23712484.0000 - mse: 23712484.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22798786.0000 - mse: 22798786.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22738766.0000 - mse: 22738766.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22263158.0000 - mse: 22263158.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21032358.0000 - mse: 21032358.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22132570.0000 - mse: 22132570.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22237612.0000 - mse: 22237612.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25174724.0000 - mse: 25174724.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23285820.0000 - mse: 23285820.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23947446.0000 - mse: 23947446.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22789430.0000 - mse: 22789430.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23934182.0000 - mse: 23934182.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23008772.0000 - mse: 23008772.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24315964.0000 - mse: 24315964.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23474866.0000 - mse: 23474866.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21984846.0000 - mse: 21984846.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22446858.0000 - mse: 22446858.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23828002.0000 - mse: 23828002.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24361636.0000 - mse: 24361636.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22813126.0000 - mse: 22813126.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21981554.0000 - mse: 21981554.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22640190.0000 - mse: 22640190.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24335502.0000 - mse: 24335502.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23980934.0000 - mse: 23980934.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23646870.0000 - mse: 23646870.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22403790.0000 - mse: 22403790.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 145881008.0000 - mse: 145881008.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63439948.0000 - mse: 63439948.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47865440.0000 - mse: 47865440.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43704820.0000 - mse: 43704820.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46549460.0000 - mse: 46549460.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48839608.0000 - mse: 48839608.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49695204.0000 - mse: 49695204.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56066768.0000 - mse: 56066768.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53471708.0000 - mse: 53471708.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56589372.0000 - mse: 56589372.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51589536.0000 - mse: 51589536.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49876036.0000 - mse: 49876036.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49248816.0000 - mse: 49248816.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45496412.0000 - mse: 45496412.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47414220.0000 - mse: 47414220.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65180832.0000 - mse: 65180832.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57062704.0000 - mse: 57062704.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49840828.0000 - mse: 49840828.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48778456.0000 - mse: 48778456.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45752208.0000 - mse: 45752208.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55006396.0000 - mse: 55006396.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51061580.0000 - mse: 51061580.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42075296.0000 - mse: 42075296.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42346232.0000 - mse: 42346232.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49082724.0000 - mse: 49082724.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 65096352.0000 - mse: 65096352.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59530112.0000 - mse: 59530112.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50059152.0000 - mse: 50059152.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62326236.0000 - mse: 62326236.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46689460.0000 - mse: 46689460.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58245156.0000 - mse: 58245156.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45131800.0000 - mse: 45131800.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 47141336.0000 - mse: 47141336.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 58828596.0000 - mse: 58828596.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 46622748.0000 - mse: 46622748.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56603500.0000 - mse: 56603500.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 68202816.0000 - mse: 68202816.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 47293360.0000 - mse: 47293360.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 51915612.0000 - mse: 51915612.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 47637792.0000 - mse: 47637792.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 47883592.0000 - mse: 47883592.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 57680672.0000 - mse: 57680672.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42958412.0000 - mse: 42958412.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45623884.0000 - mse: 45623884.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49881224.0000 - mse: 49881224.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44828524.0000 - mse: 44828524.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55211640.0000 - mse: 55211640.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50902144.0000 - mse: 50902144.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 52388648.0000 - mse: 52388648.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48250340.0000 - mse: 48250340.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 67203520.0000 - mse: 67203520.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43938996.0000 - mse: 43938996.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43658552.0000 - mse: 43658552.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44947504.0000 - mse: 44947504.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54398728.0000 - mse: 54398728.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49129732.0000 - mse: 49129732.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56226612.0000 - mse: 56226612.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 53066720.0000 - mse: 53066720.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46143236.0000 - mse: 46143236.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 44342928.0000 - mse: 44342928.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54581932.0000 - mse: 54581932.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 995us/step - loss: 46275092.0000 - mse: 46275092.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 60834428.0000 - mse: 60834428.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 64941920.0000 - mse: 64941920.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 47559232.0000 - mse: 47559232.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 53647848.0000 - mse: 53647848.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43634296.0000 - mse: 43634296.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 44415580.0000 - mse: 44415580.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42478008.0000 - mse: 42478008.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 954us/step - loss: 54077156.0000 - mse: 54077156.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41729492.0000 - mse: 41729492.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 54403052.0000 - mse: 54403052.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 51588252.0000 - mse: 51588252.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 926us/step - loss: 45679816.0000 - mse: 45679816.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 982us/step - loss: 49450132.0000 - mse: 49450132.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 47960348.0000 - mse: 47960348.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 931us/step - loss: 43141668.0000 - mse: 43141668.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50080712.0000 - mse: 50080712.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 45067620.0000 - mse: 45067620.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41581404.0000 - mse: 41581404.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67482544.0000 - mse: 67482544.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62032052.0000 - mse: 62032052.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42997368.0000 - mse: 42997368.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52262800.0000 - mse: 52262800.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53159704.0000 - mse: 53159704.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47599300.0000 - mse: 47599300.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54387604.0000 - mse: 54387604.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61192728.0000 - mse: 61192728.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53025300.0000 - mse: 53025300.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50395432.0000 - mse: 50395432.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48424156.0000 - mse: 48424156.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50669148.0000 - mse: 50669148.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49016592.0000 - mse: 49016592.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 52012260.0000 - mse: 52012260.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 54881584.0000 - mse: 54881584.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42533296.0000 - mse: 42533296.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52359660.0000 - mse: 52359660.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52579288.0000 - mse: 52579288.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56124232.0000 - mse: 56124232.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52805968.0000 - mse: 52805968.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48442336.0000 - mse: 48442336.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51246256.0000 - mse: 51246256.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59907528.0000 - mse: 59907528.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49919676.0000 - mse: 49919676.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 48653812.0000 - mse: 48653812.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56772360.0000 - mse: 56772360.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43658240.0000 - mse: 43658240.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 55818084.0000 - mse: 55818084.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56271728.0000 - mse: 56271728.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 45187052.0000 - mse: 45187052.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 971us/step - loss: 54513700.0000 - mse: 54513700.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50016352.0000 - mse: 50016352.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 57173640.0000 - mse: 57173640.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 937us/step - loss: 58758224.0000 - mse: 58758224.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 880us/step - loss: 48227220.0000 - mse: 48227220.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 836us/step - loss: 58961740.0000 - mse: 58961740.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59061744.0000 - mse: 59061744.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46196748.0000 - mse: 46196748.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44681492.0000 - mse: 44681492.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46702364.0000 - mse: 46702364.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55229212.0000 - mse: 55229212.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 68700264.0000 - mse: 68700264.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49950492.0000 - mse: 49950492.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43400564.0000 - mse: 43400564.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 48195348.0000 - mse: 48195348.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49820468.0000 - mse: 49820468.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51270520.0000 - mse: 51270520.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49411800.0000 - mse: 49411800.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58841860.0000 - mse: 58841860.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42455076.0000 - mse: 42455076.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50492484.0000 - mse: 50492484.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55185932.0000 - mse: 55185932.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44252584.0000 - mse: 44252584.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41686460.0000 - mse: 41686460.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45147648.0000 - mse: 45147648.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 44227164.0000 - mse: 44227164.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60515900.0000 - mse: 60515900.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 63381556.0000 - mse: 63381556.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 72509312.0000 - mse: 72509312.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 53731396.0000 - mse: 53731396.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48465268.0000 - mse: 48465268.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50174408.0000 - mse: 50174408.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 51285752.0000 - mse: 51285752.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 45289836.0000 - mse: 45289836.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 54925244.0000 - mse: 54925244.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 46335476.0000 - mse: 46335476.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49997024.0000 - mse: 49997024.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 58260564.0000 - mse: 58260564.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 65917264.0000 - mse: 65917264.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 47996120.0000 - mse: 47996120.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63139860.0000 - mse: 63139860.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44639352.0000 - mse: 44639352.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50894032.0000 - mse: 50894032.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49038248.0000 - mse: 49038248.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 52228068.0000 - mse: 52228068.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45242284.0000 - mse: 45242284.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44916440.0000 - mse: 44916440.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49980724.0000 - mse: 49980724.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59353864.0000 - mse: 59353864.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56533172.0000 - mse: 56533172.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49106976.0000 - mse: 49106976.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49641424.0000 - mse: 49641424.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59858056.0000 - mse: 59858056.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 48862604.0000 - mse: 48862604.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55900680.0000 - mse: 55900680.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43606444.0000 - mse: 43606444.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50573376.0000 - mse: 50573376.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42728260.0000 - mse: 42728260.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43340232.0000 - mse: 43340232.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 43785280.0000 - mse: 43785280.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 78533440.0000 - mse: 78533440.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55032200.0000 - mse: 55032200.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 63907296.0000 - mse: 63907296.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 58582636.0000 - mse: 58582636.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45531976.0000 - mse: 45531976.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50049100.0000 - mse: 50049100.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 64645588.0000 - mse: 64645588.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44564832.0000 - mse: 44564832.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 50742000.0000 - mse: 50742000.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42852376.0000 - mse: 42852376.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 60968288.0000 - mse: 60968288.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 45271224.0000 - mse: 45271224.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 53709380.0000 - mse: 53709380.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 68963872.0000 - mse: 68963872.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41969316.0000 - mse: 41969316.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47947028.0000 - mse: 47947028.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51669828.0000 - mse: 51669828.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46099276.0000 - mse: 46099276.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47352072.0000 - mse: 47352072.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50868380.0000 - mse: 50868380.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46935532.0000 - mse: 46935532.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40933868.0000 - mse: 40933868.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 54537908.0000 - mse: 54537908.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 49183200.0000 - mse: 49183200.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56094340.0000 - mse: 56094340.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42441820.0000 - mse: 42441820.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56504496.0000 - mse: 56504496.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58108636.0000 - mse: 58108636.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57739608.0000 - mse: 57739608.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62659996.0000 - mse: 62659996.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 61027132.0000 - mse: 61027132.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22999572.0000 - mse: 22999572.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22384478.0000 - mse: 22384478.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22968836.0000 - mse: 22968836.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22113932.0000 - mse: 22113932.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22124636.0000 - mse: 22124636.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23187118.0000 - mse: 23187118.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23903574.0000 - mse: 23903574.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22639866.0000 - mse: 22639866.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21020522.0000 - mse: 21020522.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22758740.0000 - mse: 22758740.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23216078.0000 - mse: 23216078.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22245730.0000 - mse: 22245730.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22194112.0000 - mse: 22194112.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22103274.0000 - mse: 22103274.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21421108.0000 - mse: 21421108.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23379660.0000 - mse: 23379660.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22969152.0000 - mse: 22969152.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23012378.0000 - mse: 23012378.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23326792.0000 - mse: 23326792.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23568914.0000 - mse: 23568914.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22794052.0000 - mse: 22794052.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23216360.0000 - mse: 23216360.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21928462.0000 - mse: 21928462.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22946006.0000 - mse: 22946006.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23723352.0000 - mse: 23723352.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23055332.0000 - mse: 23055332.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23095276.0000 - mse: 23095276.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22081328.0000 - mse: 22081328.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24958672.0000 - mse: 24958672.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23815586.0000 - mse: 23815586.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22009310.0000 - mse: 22009310.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22001700.0000 - mse: 22001700.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22054812.0000 - mse: 22054812.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22145692.0000 - mse: 22145692.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23285766.0000 - mse: 23285766.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22706672.0000 - mse: 22706672.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23062412.0000 - mse: 23062412.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22708222.0000 - mse: 22708222.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23848122.0000 - mse: 23848122.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24712582.0000 - mse: 24712582.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21560814.0000 - mse: 21560814.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23718386.0000 - mse: 23718386.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23157504.0000 - mse: 23157504.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22588134.0000 - mse: 22588134.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22071164.0000 - mse: 22071164.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21960862.0000 - mse: 21960862.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22905294.0000 - mse: 22905294.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23541560.0000 - mse: 23541560.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22056904.0000 - mse: 22056904.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21845266.0000 - mse: 21845266.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22229096.0000 - mse: 22229096.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22538602.0000 - mse: 22538602.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22386782.0000 - mse: 22386782.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23699422.0000 - mse: 23699422.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22083316.0000 - mse: 22083316.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23321810.0000 - mse: 23321810.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22412732.0000 - mse: 22412732.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22889478.0000 - mse: 22889478.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23949284.0000 - mse: 23949284.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25935492.0000 - mse: 25935492.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21577468.0000 - mse: 21577468.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22931372.0000 - mse: 22931372.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22324830.0000 - mse: 22324830.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25356110.0000 - mse: 25356110.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24252738.0000 - mse: 24252738.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23816218.0000 - mse: 23816218.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22226448.0000 - mse: 22226448.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21545504.0000 - mse: 21545504.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21714442.0000 - mse: 21714442.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24788398.0000 - mse: 24788398.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24168538.0000 - mse: 24168538.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22510550.0000 - mse: 22510550.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23621786.0000 - mse: 23621786.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23274804.0000 - mse: 23274804.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 24431466.0000 - mse: 24431466.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22151942.0000 - mse: 22151942.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22950364.0000 - mse: 22950364.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21923462.0000 - mse: 21923462.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24326448.0000 - mse: 24326448.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22518176.0000 - mse: 22518176.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22087914.0000 - mse: 22087914.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23146794.0000 - mse: 23146794.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22491300.0000 - mse: 22491300.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22158392.0000 - mse: 22158392.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21322870.0000 - mse: 21322870.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22206362.0000 - mse: 22206362.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22988536.0000 - mse: 22988536.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22989948.0000 - mse: 22989948.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21557776.0000 - mse: 21557776.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21303152.0000 - mse: 21303152.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22769704.0000 - mse: 22769704.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22221772.0000 - mse: 22221772.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22758048.0000 - mse: 22758048.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22944098.0000 - mse: 22944098.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23217290.0000 - mse: 23217290.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21972308.0000 - mse: 21972308.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23257000.0000 - mse: 23257000.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23099524.0000 - mse: 23099524.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22906536.0000 - mse: 22906536.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22827336.0000 - mse: 22827336.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22544206.0000 - mse: 22544206.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22606980.0000 - mse: 22606980.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22949826.0000 - mse: 22949826.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23186698.0000 - mse: 23186698.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23208770.0000 - mse: 23208770.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22161470.0000 - mse: 22161470.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24190402.0000 - mse: 24190402.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22210674.0000 - mse: 22210674.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22138958.0000 - mse: 22138958.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22967324.0000 - mse: 22967324.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22388174.0000 - mse: 22388174.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22671526.0000 - mse: 22671526.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22436800.0000 - mse: 22436800.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22110418.0000 - mse: 22110418.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21700158.0000 - mse: 21700158.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22737678.0000 - mse: 22737678.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22643950.0000 - mse: 22643950.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22584878.0000 - mse: 22584878.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23333462.0000 - mse: 23333462.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22950496.0000 - mse: 22950496.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22682198.0000 - mse: 22682198.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22585980.0000 - mse: 22585980.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22577536.0000 - mse: 22577536.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21651096.0000 - mse: 21651096.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23577014.0000 - mse: 23577014.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23689686.0000 - mse: 23689686.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22883276.0000 - mse: 22883276.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22983568.0000 - mse: 22983568.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22894484.0000 - mse: 22894484.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22589090.0000 - mse: 22589090.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25676766.0000 - mse: 25676766.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22931102.0000 - mse: 22931102.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22516598.0000 - mse: 22516598.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22023544.0000 - mse: 22023544.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22020178.0000 - mse: 22020178.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23514206.0000 - mse: 23514206.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22816794.0000 - mse: 22816794.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21971218.0000 - mse: 21971218.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22335584.0000 - mse: 22335584.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23139394.0000 - mse: 23139394.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22944418.0000 - mse: 22944418.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22347706.0000 - mse: 22347706.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22974436.0000 - mse: 22974436.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22577762.0000 - mse: 22577762.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22629810.0000 - mse: 22629810.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22235738.0000 - mse: 22235738.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21974384.0000 - mse: 21974384.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22936708.0000 - mse: 22936708.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 23758590.0000 - mse: 23758590.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24171946.0000 - mse: 24171946.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24210810.0000 - mse: 24210810.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22313158.0000 - mse: 22313158.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23984542.0000 - mse: 23984542.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21227146.0000 - mse: 21227146.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24640142.0000 - mse: 24640142.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22516928.0000 - mse: 22516928.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23060632.0000 - mse: 23060632.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22980096.0000 - mse: 22980096.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22108828.0000 - mse: 22108828.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21861472.0000 - mse: 21861472.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21713582.0000 - mse: 21713582.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21861006.0000 - mse: 21861006.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22435918.0000 - mse: 22435918.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22365582.0000 - mse: 22365582.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21814274.0000 - mse: 21814274.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23162260.0000 - mse: 23162260.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21900650.0000 - mse: 21900650.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24188316.0000 - mse: 24188316.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21831686.0000 - mse: 21831686.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21722496.0000 - mse: 21722496.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23242046.0000 - mse: 23242046.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22059666.0000 - mse: 22059666.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23620526.0000 - mse: 23620526.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23435378.0000 - mse: 23435378.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22757932.0000 - mse: 22757932.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22155540.0000 - mse: 22155540.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22777712.0000 - mse: 22777712.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22584908.0000 - mse: 22584908.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21813994.0000 - mse: 21813994.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23292226.0000 - mse: 23292226.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22285178.0000 - mse: 22285178.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22777006.0000 - mse: 22777006.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24655290.0000 - mse: 24655290.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22158076.0000 - mse: 22158076.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22823278.0000 - mse: 22823278.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22172052.0000 - mse: 22172052.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22052212.0000 - mse: 22052212.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22506292.0000 - mse: 22506292.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22217182.0000 - mse: 22217182.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22971098.0000 - mse: 22971098.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23669202.0000 - mse: 23669202.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26686048.0000 - mse: 26686048.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22122146.0000 - mse: 22122146.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22255016.0000 - mse: 22255016.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23258298.0000 - mse: 23258298.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23086820.0000 - mse: 23086820.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21317320.0000 - mse: 21317320.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24196106.0000 - mse: 24196106.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21824944.0000 - mse: 21824944.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 97810520.0000 - mse: 97810520.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 46762840.0000 - mse: 46762840.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36929668.0000 - mse: 36929668.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36849196.0000 - mse: 36849196.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39846516.0000 - mse: 39846516.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35105436.0000 - mse: 35105436.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37372032.0000 - mse: 37372032.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39567616.0000 - mse: 39567616.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38085944.0000 - mse: 38085944.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40114596.0000 - mse: 40114596.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38758720.0000 - mse: 38758720.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39028092.0000 - mse: 39028092.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40359540.0000 - mse: 40359540.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37621724.0000 - mse: 37621724.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38490876.0000 - mse: 38490876.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 44524532.0000 - mse: 44524532.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38583308.0000 - mse: 38583308.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36351724.0000 - mse: 36351724.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37763944.0000 - mse: 37763944.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41384128.0000 - mse: 41384128.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39788812.0000 - mse: 39788812.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39213992.0000 - mse: 39213992.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35922596.0000 - mse: 35922596.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38633760.0000 - mse: 38633760.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38374192.0000 - mse: 38374192.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41955916.0000 - mse: 41955916.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37005924.0000 - mse: 37005924.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37303272.0000 - mse: 37303272.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37346392.0000 - mse: 37346392.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38183296.0000 - mse: 38183296.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37124976.0000 - mse: 37124976.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39267620.0000 - mse: 39267620.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36255452.0000 - mse: 36255452.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36530756.0000 - mse: 36530756.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37426628.0000 - mse: 37426628.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39151612.0000 - mse: 39151612.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40895088.0000 - mse: 40895088.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39701680.0000 - mse: 39701680.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36633148.0000 - mse: 36633148.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39912704.0000 - mse: 39912704.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36910164.0000 - mse: 36910164.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37119616.0000 - mse: 37119616.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39350892.0000 - mse: 39350892.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37278700.0000 - mse: 37278700.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37136824.0000 - mse: 37136824.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37763452.0000 - mse: 37763452.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 948us/step - loss: 38279788.0000 - mse: 38279788.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37197064.0000 - mse: 37197064.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38165504.0000 - mse: 38165504.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37027512.0000 - mse: 37027512.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38590672.0000 - mse: 38590672.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42693184.0000 - mse: 42693184.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38896976.0000 - mse: 38896976.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38273972.0000 - mse: 38273972.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37301336.0000 - mse: 37301336.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36436676.0000 - mse: 36436676.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37723552.0000 - mse: 37723552.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38179836.0000 - mse: 38179836.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35299744.0000 - mse: 35299744.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39393908.0000 - mse: 39393908.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37505240.0000 - mse: 37505240.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40747348.0000 - mse: 40747348.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37196792.0000 - mse: 37196792.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36527260.0000 - mse: 36527260.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36489484.0000 - mse: 36489484.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37553824.0000 - mse: 37553824.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37466560.0000 - mse: 37466560.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37288144.0000 - mse: 37288144.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36299876.0000 - mse: 36299876.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35914240.0000 - mse: 35914240.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36483184.0000 - mse: 36483184.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36589368.0000 - mse: 36589368.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41538424.0000 - mse: 41538424.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41610848.0000 - mse: 41610848.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36525868.0000 - mse: 36525868.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 37782680.0000 - mse: 37782680.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36884216.0000 - mse: 36884216.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39055012.0000 - mse: 39055012.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35933268.0000 - mse: 35933268.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35898972.0000 - mse: 35898972.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37559220.0000 - mse: 37559220.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38671220.0000 - mse: 38671220.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37125552.0000 - mse: 37125552.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38559300.0000 - mse: 38559300.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37686580.0000 - mse: 37686580.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37304532.0000 - mse: 37304532.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37954028.0000 - mse: 37954028.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37041076.0000 - mse: 37041076.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37637100.0000 - mse: 37637100.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36985968.0000 - mse: 36985968.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38513576.0000 - mse: 38513576.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37778608.0000 - mse: 37778608.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36576996.0000 - mse: 36576996.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37336672.0000 - mse: 37336672.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36649276.0000 - mse: 36649276.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38298248.0000 - mse: 38298248.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39978392.0000 - mse: 39978392.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36194760.0000 - mse: 36194760.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40905872.0000 - mse: 40905872.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37477668.0000 - mse: 37477668.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37214320.0000 - mse: 37214320.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37284964.0000 - mse: 37284964.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38208596.0000 - mse: 38208596.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35985552.0000 - mse: 35985552.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40733856.0000 - mse: 40733856.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38698368.0000 - mse: 38698368.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36996060.0000 - mse: 36996060.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40755248.0000 - mse: 40755248.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37750720.0000 - mse: 37750720.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35211388.0000 - mse: 35211388.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37197372.0000 - mse: 37197372.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36985104.0000 - mse: 36985104.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35803500.0000 - mse: 35803500.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39258044.0000 - mse: 39258044.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37682364.0000 - mse: 37682364.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38149124.0000 - mse: 38149124.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37072528.0000 - mse: 37072528.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37693056.0000 - mse: 37693056.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37529660.0000 - mse: 37529660.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36746912.0000 - mse: 36746912.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39073568.0000 - mse: 39073568.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36328972.0000 - mse: 36328972.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37286488.0000 - mse: 37286488.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37558200.0000 - mse: 37558200.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38186124.0000 - mse: 38186124.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40401012.0000 - mse: 40401012.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37199256.0000 - mse: 37199256.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40512456.0000 - mse: 40512456.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38310776.0000 - mse: 38310776.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36285420.0000 - mse: 36285420.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35365272.0000 - mse: 35365272.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37765644.0000 - mse: 37765644.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 40173380.0000 - mse: 40173380.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38715876.0000 - mse: 38715876.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37032696.0000 - mse: 37032696.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42829132.0000 - mse: 42829132.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38206092.0000 - mse: 38206092.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38224224.0000 - mse: 38224224.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37039720.0000 - mse: 37039720.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39910020.0000 - mse: 39910020.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42106540.0000 - mse: 42106540.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38391164.0000 - mse: 38391164.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36682328.0000 - mse: 36682328.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37099528.0000 - mse: 37099528.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38292772.0000 - mse: 38292772.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38098996.0000 - mse: 38098996.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37588652.0000 - mse: 37588652.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37523436.0000 - mse: 37523436.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36841876.0000 - mse: 36841876.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 39617636.0000 - mse: 39617636.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 42495340.0000 - mse: 42495340.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39201140.0000 - mse: 39201140.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36439580.0000 - mse: 36439580.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39040380.0000 - mse: 39040380.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37023268.0000 - mse: 37023268.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37267008.0000 - mse: 37267008.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38407552.0000 - mse: 38407552.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38050000.0000 - mse: 38050000.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37662676.0000 - mse: 37662676.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38483956.0000 - mse: 38483956.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37315748.0000 - mse: 37315748.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39237788.0000 - mse: 39237788.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 41716328.0000 - mse: 41716328.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39615532.0000 - mse: 39615532.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36270208.0000 - mse: 36270208.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37249740.0000 - mse: 37249740.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37624260.0000 - mse: 37624260.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36970764.0000 - mse: 36970764.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39500220.0000 - mse: 39500220.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37208636.0000 - mse: 37208636.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36068176.0000 - mse: 36068176.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36211124.0000 - mse: 36211124.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38645192.0000 - mse: 38645192.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37336140.0000 - mse: 37336140.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36056772.0000 - mse: 36056772.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39005392.0000 - mse: 39005392.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38702844.0000 - mse: 38702844.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37246212.0000 - mse: 37246212.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39217504.0000 - mse: 39217504.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38441340.0000 - mse: 38441340.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38053440.0000 - mse: 38053440.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36589072.0000 - mse: 36589072.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37816432.0000 - mse: 37816432.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37125276.0000 - mse: 37125276.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 39295544.0000 - mse: 39295544.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 35922600.0000 - mse: 35922600.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37506060.0000 - mse: 37506060.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38268992.0000 - mse: 38268992.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36825036.0000 - mse: 36825036.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38538308.0000 - mse: 38538308.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37006640.0000 - mse: 37006640.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 38451868.0000 - mse: 38451868.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37799416.0000 - mse: 37799416.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 37493768.0000 - mse: 37493768.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 36026360.0000 - mse: 36026360.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36564732.0000 - mse: 36564732.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39226636.0000 - mse: 39226636.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36513708.0000 - mse: 36513708.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40913520.0000 - mse: 40913520.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38616016.0000 - mse: 38616016.0000\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 85118840.0000 - mse: 85118840.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33317716.0000 - mse: 33317716.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31644026.0000 - mse: 31644026.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34276076.0000 - mse: 34276076.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32155378.0000 - mse: 32155378.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32315674.0000 - mse: 32315674.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25251074.0000 - mse: 25251074.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26955798.0000 - mse: 26955798.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24995604.0000 - mse: 24995604.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25760682.0000 - mse: 25760682.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25907728.0000 - mse: 25907728.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26470708.0000 - mse: 26470708.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25694182.0000 - mse: 25694182.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25187292.0000 - mse: 25187292.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25078162.0000 - mse: 25078162.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24368022.0000 - mse: 24368022.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24476956.0000 - mse: 24476956.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24892276.0000 - mse: 24892276.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25873568.0000 - mse: 25873568.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24132132.0000 - mse: 24132132.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26655672.0000 - mse: 26655672.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24352190.0000 - mse: 24352190.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25825526.0000 - mse: 25825526.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26535790.0000 - mse: 26535790.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24779262.0000 - mse: 24779262.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27588560.0000 - mse: 27588560.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26450068.0000 - mse: 26450068.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25627250.0000 - mse: 25627250.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25952012.0000 - mse: 25952012.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27182676.0000 - mse: 27182676.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25471714.0000 - mse: 25471714.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26387134.0000 - mse: 26387134.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25243394.0000 - mse: 25243394.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26080856.0000 - mse: 26080856.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26588418.0000 - mse: 26588418.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26538948.0000 - mse: 26538948.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24222416.0000 - mse: 24222416.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27054146.0000 - mse: 27054146.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25611312.0000 - mse: 25611312.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25468100.0000 - mse: 25468100.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24758874.0000 - mse: 24758874.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26392072.0000 - mse: 26392072.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25729996.0000 - mse: 25729996.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27385078.0000 - mse: 27385078.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25132208.0000 - mse: 25132208.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26237124.0000 - mse: 26237124.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25263646.0000 - mse: 25263646.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25138370.0000 - mse: 25138370.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24742222.0000 - mse: 24742222.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26760324.0000 - mse: 26760324.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26330104.0000 - mse: 26330104.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25001968.0000 - mse: 25001968.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25675050.0000 - mse: 25675050.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25399670.0000 - mse: 25399670.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24594282.0000 - mse: 24594282.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24239246.0000 - mse: 24239246.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24227858.0000 - mse: 24227858.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26255834.0000 - mse: 26255834.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26299818.0000 - mse: 26299818.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26991932.0000 - mse: 26991932.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26124136.0000 - mse: 26124136.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25252456.0000 - mse: 25252456.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27318776.0000 - mse: 27318776.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26699138.0000 - mse: 26699138.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26119604.0000 - mse: 26119604.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25897970.0000 - mse: 25897970.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25591182.0000 - mse: 25591182.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26603424.0000 - mse: 26603424.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24886190.0000 - mse: 24886190.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25638006.0000 - mse: 25638006.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27262994.0000 - mse: 27262994.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26497786.0000 - mse: 26497786.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25492428.0000 - mse: 25492428.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25188532.0000 - mse: 25188532.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26935708.0000 - mse: 26935708.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 24962732.0000 - mse: 24962732.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26070568.0000 - mse: 26070568.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26435708.0000 - mse: 26435708.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25654122.0000 - mse: 25654122.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25145462.0000 - mse: 25145462.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26519256.0000 - mse: 26519256.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26777642.0000 - mse: 26777642.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24371316.0000 - mse: 24371316.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25560832.0000 - mse: 25560832.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26447096.0000 - mse: 26447096.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26384966.0000 - mse: 26384966.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27957022.0000 - mse: 27957022.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26196566.0000 - mse: 26196566.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25843484.0000 - mse: 25843484.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27307084.0000 - mse: 27307084.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25964584.0000 - mse: 25964584.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27307772.0000 - mse: 27307772.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24230902.0000 - mse: 24230902.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26046614.0000 - mse: 26046614.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25179446.0000 - mse: 25179446.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25858348.0000 - mse: 25858348.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25734894.0000 - mse: 25734894.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24363258.0000 - mse: 24363258.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27390536.0000 - mse: 27390536.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25263232.0000 - mse: 25263232.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27388858.0000 - mse: 27388858.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27438802.0000 - mse: 27438802.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24100846.0000 - mse: 24100846.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23486256.0000 - mse: 23486256.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25739576.0000 - mse: 25739576.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27448302.0000 - mse: 27448302.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25430804.0000 - mse: 25430804.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25726776.0000 - mse: 25726776.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28594810.0000 - mse: 28594810.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25674624.0000 - mse: 25674624.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24894888.0000 - mse: 24894888.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24756476.0000 - mse: 24756476.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25896748.0000 - mse: 25896748.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25682648.0000 - mse: 25682648.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24589114.0000 - mse: 24589114.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27350672.0000 - mse: 27350672.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27470848.0000 - mse: 27470848.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25554074.0000 - mse: 25554074.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24910698.0000 - mse: 24910698.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27104890.0000 - mse: 27104890.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24501394.0000 - mse: 24501394.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24883898.0000 - mse: 24883898.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25044570.0000 - mse: 25044570.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26295862.0000 - mse: 26295862.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24878580.0000 - mse: 24878580.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26629660.0000 - mse: 26629662.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24864962.0000 - mse: 24864962.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25331804.0000 - mse: 25331804.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24509904.0000 - mse: 24509904.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25108780.0000 - mse: 25108780.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26157914.0000 - mse: 26157914.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25281306.0000 - mse: 25281306.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25419684.0000 - mse: 25419684.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24944166.0000 - mse: 24944166.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28200986.0000 - mse: 28200986.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25239590.0000 - mse: 25239590.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25644774.0000 - mse: 25644774.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25389680.0000 - mse: 25389680.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26124794.0000 - mse: 26124794.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24913596.0000 - mse: 24913596.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26265340.0000 - mse: 26265340.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25354982.0000 - mse: 25354982.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27573204.0000 - mse: 27573204.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24855338.0000 - mse: 24855338.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24885062.0000 - mse: 24885062.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25318004.0000 - mse: 25318004.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25012918.0000 - mse: 25012918.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25099820.0000 - mse: 25099820.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24526108.0000 - mse: 24526108.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 25443006.0000 - mse: 25443006.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24694272.0000 - mse: 24694272.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27451128.0000 - mse: 27451128.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24385890.0000 - mse: 24385890.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29312068.0000 - mse: 29312068.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25415040.0000 - mse: 25415040.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26021330.0000 - mse: 26021330.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27509256.0000 - mse: 27509256.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25651048.0000 - mse: 25651048.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25165070.0000 - mse: 25165070.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25604598.0000 - mse: 25604598.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24928216.0000 - mse: 24928216.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26856450.0000 - mse: 26856450.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24466168.0000 - mse: 24466168.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 998us/step - loss: 26973544.0000 - mse: 26973544.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24808256.0000 - mse: 24808256.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 999us/step - loss: 25988560.0000 - mse: 25988560.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 997us/step - loss: 27234248.0000 - mse: 27234248.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29951764.0000 - mse: 29951764.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25483244.0000 - mse: 25483244.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26017032.0000 - mse: 26017032.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27064482.0000 - mse: 27064482.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24622610.0000 - mse: 24622610.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25936864.0000 - mse: 25936864.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23842398.0000 - mse: 23842398.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 884us/step - loss: 24289470.0000 - mse: 24289470.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25843964.0000 - mse: 25843964.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27384668.0000 - mse: 27384668.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26413024.0000 - mse: 26413024.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25623334.0000 - mse: 25623334.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25238818.0000 - mse: 25238818.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25356366.0000 - mse: 25356366.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25512884.0000 - mse: 25512884.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27404270.0000 - mse: 27404270.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24863610.0000 - mse: 24863610.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27299576.0000 - mse: 27299576.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27091118.0000 - mse: 27091118.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27215306.0000 - mse: 27215306.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26196196.0000 - mse: 26196196.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25800012.0000 - mse: 25800012.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24563052.0000 - mse: 24563052.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24975008.0000 - mse: 24975008.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25445850.0000 - mse: 25445850.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24150918.0000 - mse: 24150918.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27174734.0000 - mse: 27174734.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25698798.0000 - mse: 25698798.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26268198.0000 - mse: 26268198.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25398088.0000 - mse: 25398088.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25671860.0000 - mse: 25671860.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25276852.0000 - mse: 25276852.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27044892.0000 - mse: 27044892.0000\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 92558160.0000 - mse: 92558160.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27667564.0000 - mse: 27667564.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21582870.0000 - mse: 21582870.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20654736.0000 - mse: 20654736.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20176482.0000 - mse: 20176482.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21019794.0000 - mse: 21019794.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21510492.0000 - mse: 21510492.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21265920.0000 - mse: 21265920.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21791978.0000 - mse: 21791978.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21095846.0000 - mse: 21095846.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21682872.0000 - mse: 21682872.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21372630.0000 - mse: 21372630.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20512628.0000 - mse: 20512628.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20779908.0000 - mse: 20779908.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19968490.0000 - mse: 19968490.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19536392.0000 - mse: 19536392.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20088862.0000 - mse: 20088862.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20781942.0000 - mse: 20781942.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20552082.0000 - mse: 20552082.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20485360.0000 - mse: 20485360.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20897794.0000 - mse: 20897794.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19744314.0000 - mse: 19744314.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 948us/step - loss: 20398012.0000 - mse: 20398012.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 986us/step - loss: 20368652.0000 - mse: 20368652.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 921us/step - loss: 20970620.0000 - mse: 20970620.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 860us/step - loss: 20076020.0000 - mse: 20076020.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 996us/step - loss: 19852024.0000 - mse: 19852024.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 949us/step - loss: 19725408.0000 - mse: 19725408.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 920us/step - loss: 20277758.0000 - mse: 20277758.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20196176.0000 - mse: 20196176.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20366276.0000 - mse: 20366276.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21127870.0000 - mse: 21127870.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19664276.0000 - mse: 19664276.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20452784.0000 - mse: 20452784.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20302324.0000 - mse: 20302324.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21542920.0000 - mse: 21542920.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19557142.0000 - mse: 19557142.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20978304.0000 - mse: 20978304.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21453012.0000 - mse: 21453012.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20864052.0000 - mse: 20864052.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19912424.0000 - mse: 19912424.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 20089940.0000 - mse: 20089940.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20670452.0000 - mse: 20670452.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21727926.0000 - mse: 21727926.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20331140.0000 - mse: 20331140.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20746782.0000 - mse: 20746782.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20600904.0000 - mse: 20600904.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20237924.0000 - mse: 20237924.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19805892.0000 - mse: 19805892.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20154822.0000 - mse: 20154822.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21365914.0000 - mse: 21365914.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20734452.0000 - mse: 20734452.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22516992.0000 - mse: 22516992.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21086302.0000 - mse: 21086302.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20794518.0000 - mse: 20794518.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20066298.0000 - mse: 20066298.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20979108.0000 - mse: 20979108.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20589376.0000 - mse: 20589376.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20712294.0000 - mse: 20712294.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21568192.0000 - mse: 21568192.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20599814.0000 - mse: 20599814.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21512028.0000 - mse: 21512028.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20307254.0000 - mse: 20307254.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21176410.0000 - mse: 21176410.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20646236.0000 - mse: 20646236.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20171634.0000 - mse: 20171634.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20907038.0000 - mse: 20907038.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20250348.0000 - mse: 20250348.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20326914.0000 - mse: 20326914.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19595978.0000 - mse: 19595978.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21174884.0000 - mse: 21174884.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20129500.0000 - mse: 20129500.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20614330.0000 - mse: 20614330.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20966924.0000 - mse: 20966924.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20587972.0000 - mse: 20587972.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 20247588.0000 - mse: 20247588.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20757962.0000 - mse: 20757962.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20863554.0000 - mse: 20863554.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19866986.0000 - mse: 19866986.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20446492.0000 - mse: 20446492.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19493904.0000 - mse: 19493904.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20839682.0000 - mse: 20839682.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20215116.0000 - mse: 20215116.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 970us/step - loss: 20656420.0000 - mse: 20656420.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19957482.0000 - mse: 19957482.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19577760.0000 - mse: 19577760.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19756632.0000 - mse: 19756632.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20630692.0000 - mse: 20630692.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23499780.0000 - mse: 23499780.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 945us/step - loss: 20819098.0000 - mse: 20819098.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21309080.0000 - mse: 21309080.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 960us/step - loss: 21986834.0000 - mse: 21986834.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20149726.0000 - mse: 20149726.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20982228.0000 - mse: 20982228.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20238282.0000 - mse: 20238282.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20568322.0000 - mse: 20568322.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20557048.0000 - mse: 20557048.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20841888.0000 - mse: 20841888.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19490052.0000 - mse: 19490052.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19964208.0000 - mse: 19964208.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20586544.0000 - mse: 20586544.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20939436.0000 - mse: 20939436.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19942870.0000 - mse: 19942870.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19337440.0000 - mse: 19337440.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20388562.0000 - mse: 20388562.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20135188.0000 - mse: 20135188.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21353546.0000 - mse: 21353546.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21340748.0000 - mse: 21340748.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20427790.0000 - mse: 20427790.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20340630.0000 - mse: 20340630.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21126232.0000 - mse: 21126232.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19677058.0000 - mse: 19677058.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20144638.0000 - mse: 20144638.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20737648.0000 - mse: 20737648.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21517806.0000 - mse: 21517806.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21958026.0000 - mse: 21958026.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20570734.0000 - mse: 20570734.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20762306.0000 - mse: 20762306.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20385660.0000 - mse: 20385660.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20558264.0000 - mse: 20558264.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20420678.0000 - mse: 20420678.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21545506.0000 - mse: 21545506.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19990168.0000 - mse: 19990168.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20757936.0000 - mse: 20757936.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20636916.0000 - mse: 20636916.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21526694.0000 - mse: 21526694.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20813046.0000 - mse: 20813046.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20882106.0000 - mse: 20882106.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21593712.0000 - mse: 21593712.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20184298.0000 - mse: 20184298.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20207414.0000 - mse: 20207414.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20867750.0000 - mse: 20867750.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19916014.0000 - mse: 19916014.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19999264.0000 - mse: 19999264.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20174842.0000 - mse: 20174842.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20255938.0000 - mse: 20255938.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20328974.0000 - mse: 20328974.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21447790.0000 - mse: 21447790.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20701120.0000 - mse: 20701120.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20535418.0000 - mse: 20535418.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20145694.0000 - mse: 20145694.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20196728.0000 - mse: 20196728.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19655142.0000 - mse: 19655142.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22786682.0000 - mse: 22786682.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20391628.0000 - mse: 20391628.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20414264.0000 - mse: 20414264.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19321512.0000 - mse: 19321512.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20284984.0000 - mse: 20284984.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20510340.0000 - mse: 20510340.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 20242116.0000 - mse: 20242116.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21391910.0000 - mse: 21391910.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20543296.0000 - mse: 20543296.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19792636.0000 - mse: 19792636.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21331394.0000 - mse: 21331394.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20789156.0000 - mse: 20789156.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20706550.0000 - mse: 20706550.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19856530.0000 - mse: 19856530.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21174460.0000 - mse: 21174460.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20562886.0000 - mse: 20562886.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20901862.0000 - mse: 20901862.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20306240.0000 - mse: 20306240.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20535482.0000 - mse: 20535482.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20837906.0000 - mse: 20837906.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 973us/step - loss: 20978122.0000 - mse: 20978122.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20396606.0000 - mse: 20396606.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20083174.0000 - mse: 20083174.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19899182.0000 - mse: 19899182.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 865us/step - loss: 22609792.0000 - mse: 22609792.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22276732.0000 - mse: 22276732.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21499084.0000 - mse: 21499084.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20333646.0000 - mse: 20333646.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20395526.0000 - mse: 20395526.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20392982.0000 - mse: 20392982.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19702044.0000 - mse: 19702044.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21627950.0000 - mse: 21627950.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20652812.0000 - mse: 20652812.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20543466.0000 - mse: 20543466.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 19885266.0000 - mse: 19885266.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20045822.0000 - mse: 20045822.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 20242924.0000 - mse: 20242924.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20556998.0000 - mse: 20556998.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21611538.0000 - mse: 21611538.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22247596.0000 - mse: 22247596.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20683006.0000 - mse: 20683006.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19874864.0000 - mse: 19874864.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21127370.0000 - mse: 21127370.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 19923588.0000 - mse: 19923588.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21085844.0000 - mse: 21085844.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20854458.0000 - mse: 20854458.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20506090.0000 - mse: 20506090.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21466422.0000 - mse: 21466422.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21215904.0000 - mse: 21215904.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 21959510.0000 - mse: 21959510.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20267408.0000 - mse: 20267408.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20039102.0000 - mse: 20039102.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20330222.0000 - mse: 20330222.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 21248782.0000 - mse: 21248782.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20206772.0000 - mse: 20206772.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20625892.0000 - mse: 20625892.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 20620420.0000 - mse: 20620420.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 187775792.0000 - mse: 187775792.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73502496.0000 - mse: 73502496.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68077376.0000 - mse: 68077376.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 77338304.0000 - mse: 77338304.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48803272.0000 - mse: 48803272.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57409236.0000 - mse: 57409236.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67390200.0000 - mse: 67390200.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75242440.0000 - mse: 75242440.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68650992.0000 - mse: 68650992.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72827600.0000 - mse: 72827600.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72261584.0000 - mse: 72261584.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63682396.0000 - mse: 63682396.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62665548.0000 - mse: 62665548.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53288860.0000 - mse: 53288860.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56990220.0000 - mse: 56990220.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 79682528.0000 - mse: 79682528.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66150552.0000 - mse: 66150552.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 69355176.0000 - mse: 69355176.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54726876.0000 - mse: 54726876.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59676256.0000 - mse: 59676256.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70079544.0000 - mse: 70079544.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67057248.0000 - mse: 67057248.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60525100.0000 - mse: 60525100.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61207696.0000 - mse: 61207696.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65577072.0000 - mse: 65577072.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68845368.0000 - mse: 68845368.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 74133528.0000 - mse: 74133528.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64450028.0000 - mse: 64450028.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70185648.0000 - mse: 70185648.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 68694096.0000 - mse: 68694096.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 62572792.0000 - mse: 62572792.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61683260.0000 - mse: 61683260.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 58941752.0000 - mse: 58941752.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68946600.0000 - mse: 68946600.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 62908952.0000 - mse: 62908952.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 89295488.0000 - mse: 89295488.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71992960.0000 - mse: 71992960.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 56913696.0000 - mse: 56913696.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 96547056.0000 - mse: 96547056.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59082868.0000 - mse: 59082868.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60781944.0000 - mse: 60781944.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 67598744.0000 - mse: 67598744.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52099588.0000 - mse: 52099588.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53264928.0000 - mse: 53264928.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58465848.0000 - mse: 58465848.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 55305132.0000 - mse: 55305132.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63256700.0000 - mse: 63256700.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73700280.0000 - mse: 73700280.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66439612.0000 - mse: 66439612.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62287188.0000 - mse: 62287188.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 103797416.0000 - mse: 103797416.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63927132.0000 - mse: 63927132.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58971844.0000 - mse: 58971844.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67971576.0000 - mse: 67971576.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70267032.0000 - mse: 70267032.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 57121724.0000 - mse: 57121724.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 852us/step - loss: 67287336.0000 - mse: 67287336.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64488328.0000 - mse: 64488328.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58519924.0000 - mse: 58519924.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55484840.0000 - mse: 55484840.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66331696.0000 - mse: 66331696.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59062792.0000 - mse: 59062796.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 91744744.0000 - mse: 91744744.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 102383776.0000 - mse: 102383776.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72191328.0000 - mse: 72191328.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68019816.0000 - mse: 68019816.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53726612.0000 - mse: 53726612.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56914100.0000 - mse: 56914100.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57379280.0000 - mse: 57379280.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61139284.0000 - mse: 61139284.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52006804.0000 - mse: 52006804.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 85015288.0000 - mse: 85015288.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 55912416.0000 - mse: 55912416.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56956600.0000 - mse: 56956600.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55536164.0000 - mse: 55536164.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 59532124.0000 - mse: 59532124.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57304336.0000 - mse: 57304336.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71740880.0000 - mse: 71740880.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 56136704.0000 - mse: 56136704.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 53280860.0000 - mse: 53280860.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 92566536.0000 - mse: 92566536.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 66659552.0000 - mse: 66659552.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58252688.0000 - mse: 58252688.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65154732.0000 - mse: 65154732.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56183756.0000 - mse: 56183756.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66524436.0000 - mse: 66524436.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66319332.0000 - mse: 66319332.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72449952.0000 - mse: 72449952.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 63951684.0000 - mse: 63951684.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 69161872.0000 - mse: 69161872.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62370172.0000 - mse: 62370172.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75075776.0000 - mse: 75075776.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66261016.0000 - mse: 66261016.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 76165464.0000 - mse: 76165464.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55433792.0000 - mse: 55433792.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54428660.0000 - mse: 54428660.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57662368.0000 - mse: 57662368.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56796800.0000 - mse: 56796800.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67466736.0000 - mse: 67466736.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73669408.0000 - mse: 73669408.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62268868.0000 - mse: 62268868.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73111472.0000 - mse: 73111472.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56632456.0000 - mse: 56632456.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55461992.0000 - mse: 55461992.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 55955420.0000 - mse: 55955420.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 67045624.0000 - mse: 67045624.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 61341608.0000 - mse: 61341608.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 65361568.0000 - mse: 65361568.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53848880.0000 - mse: 53848880.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52474328.0000 - mse: 52474328.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 65708520.0000 - mse: 65708520.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73702368.0000 - mse: 73702368.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 78012752.0000 - mse: 78012752.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70842528.0000 - mse: 70842528.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56484864.0000 - mse: 56484864.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 79399312.0000 - mse: 79399312.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 66987300.0000 - mse: 66987300.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59171616.0000 - mse: 59171616.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 62579200.0000 - mse: 62579200.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 66871264.0000 - mse: 66871264.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 59831944.0000 - mse: 59831944.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 68835008.0000 - mse: 68835008.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56619780.0000 - mse: 56619780.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 60387428.0000 - mse: 60387428.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 64987576.0000 - mse: 64987576.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 89829832.0000 - mse: 89829832.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 67418560.0000 - mse: 67418560.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66680660.0000 - mse: 66680660.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61297460.0000 - mse: 61297460.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55927052.0000 - mse: 55927052.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62224020.0000 - mse: 62224020.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 76914632.0000 - mse: 76914632.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55276336.0000 - mse: 55276336.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57015624.0000 - mse: 57015624.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 55562808.0000 - mse: 55562808.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53395164.0000 - mse: 53395164.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 72695432.0000 - mse: 72695432.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 72287960.0000 - mse: 72287960.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 94463392.0000 - mse: 94463392.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 66802068.0000 - mse: 66802068.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 70216800.0000 - mse: 70216800.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68767544.0000 - mse: 68767544.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65396704.0000 - mse: 65396704.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57754140.0000 - mse: 57754140.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61872740.0000 - mse: 61872740.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67968872.0000 - mse: 67968872.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 64947120.0000 - mse: 64947120.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 82108720.0000 - mse: 82108720.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75111568.0000 - mse: 75111568.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 61928764.0000 - mse: 61928764.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 89369936.0000 - mse: 89369936.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 56206892.0000 - mse: 56206892.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65169260.0000 - mse: 65169260.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62884892.0000 - mse: 62884892.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 76292112.0000 - mse: 76292112.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57729668.0000 - mse: 57729668.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 68814960.0000 - mse: 68814960.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 54552552.0000 - mse: 54552552.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 82457208.0000 - mse: 82457208.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75717600.0000 - mse: 75717600.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73201888.0000 - mse: 73201888.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58747244.0000 - mse: 58747244.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70165312.0000 - mse: 70165312.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 77525056.0000 - mse: 77525056.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61090936.0000 - mse: 61090936.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 58541128.0000 - mse: 58541128.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 74858232.0000 - mse: 74858232.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 52798676.0000 - mse: 52798676.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56224888.0000 - mse: 56224888.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52870976.0000 - mse: 52870976.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 78547440.0000 - mse: 78547440.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 63685932.0000 - mse: 63685932.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 78141608.0000 - mse: 78141608.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 60926588.0000 - mse: 60926588.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65815204.0000 - mse: 65815204.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55401752.0000 - mse: 55401752.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 95801120.0000 - mse: 95801120.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55213732.0000 - mse: 55213732.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65082908.0000 - mse: 65082908.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67556088.0000 - mse: 67556088.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63840964.0000 - mse: 63840964.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49912324.0000 - mse: 49912324.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61707660.0000 - mse: 61707660.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 85797096.0000 - mse: 85797096.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60590196.0000 - mse: 60590196.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52980880.0000 - mse: 52980880.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57211260.0000 - mse: 57211260.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56039176.0000 - mse: 56039176.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59289500.0000 - mse: 59289500.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57477832.0000 - mse: 57477832.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 57161688.0000 - mse: 57161688.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57925856.0000 - mse: 57925856.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64020952.0000 - mse: 64020952.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71256208.0000 - mse: 71256208.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63982924.0000 - mse: 63982924.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 50872576.0000 - mse: 50872576.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67864952.0000 - mse: 67864952.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68213264.0000 - mse: 68213264.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 65672248.0000 - mse: 65672248.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 66962808.0000 - mse: 66962808.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 74296664.0000 - mse: 74296664.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 33053904.0000 - mse: 33053904.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25603964.0000 - mse: 25603964.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24308598.0000 - mse: 24308598.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24200810.0000 - mse: 24200810.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24002616.0000 - mse: 24002616.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24123150.0000 - mse: 24123150.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24524812.0000 - mse: 24524812.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24003424.0000 - mse: 24003424.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22440680.0000 - mse: 22440680.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23425488.0000 - mse: 23425488.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24091772.0000 - mse: 24091772.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24161486.0000 - mse: 24161486.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24246428.0000 - mse: 24246428.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23724340.0000 - mse: 23724340.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24018296.0000 - mse: 24018296.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24344710.0000 - mse: 24344710.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23986878.0000 - mse: 23986878.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23951956.0000 - mse: 23951956.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24030702.0000 - mse: 24030702.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23045800.0000 - mse: 23045800.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24217656.0000 - mse: 24217656.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24572948.0000 - mse: 24572948.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23379862.0000 - mse: 23379862.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24443096.0000 - mse: 24443096.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23540982.0000 - mse: 23540982.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26431896.0000 - mse: 26431896.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23768338.0000 - mse: 23768336.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23648586.0000 - mse: 23648586.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25873120.0000 - mse: 25873120.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23494882.0000 - mse: 23494882.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23706488.0000 - mse: 23706488.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24248532.0000 - mse: 24248532.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23520018.0000 - mse: 23520018.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23547494.0000 - mse: 23547494.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24851798.0000 - mse: 24851798.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24778666.0000 - mse: 24778666.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24453898.0000 - mse: 24453898.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23040806.0000 - mse: 23040806.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24473936.0000 - mse: 24473936.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23459984.0000 - mse: 23459984.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24685792.0000 - mse: 24685792.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24269032.0000 - mse: 24269032.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25279358.0000 - mse: 25279358.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23085158.0000 - mse: 23085158.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23320494.0000 - mse: 23320494.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23867456.0000 - mse: 23867456.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24243940.0000 - mse: 24243940.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24973390.0000 - mse: 24973390.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23395552.0000 - mse: 23395552.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23274824.0000 - mse: 23274824.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24199836.0000 - mse: 24199836.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23947738.0000 - mse: 23947738.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23574624.0000 - mse: 23574624.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24379178.0000 - mse: 24379178.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23674002.0000 - mse: 23674002.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23219588.0000 - mse: 23219588.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25131506.0000 - mse: 25131506.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23911966.0000 - mse: 23911966.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24154172.0000 - mse: 24154172.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24580008.0000 - mse: 24580008.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23106292.0000 - mse: 23106292.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23970868.0000 - mse: 23970868.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23968256.0000 - mse: 23968256.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24059600.0000 - mse: 24059600.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24908780.0000 - mse: 24908780.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24002312.0000 - mse: 24002312.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23970278.0000 - mse: 23970278.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23456294.0000 - mse: 23456294.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23540606.0000 - mse: 23540606.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23616132.0000 - mse: 23616132.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24071240.0000 - mse: 24071240.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24391744.0000 - mse: 24391744.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24213126.0000 - mse: 24213126.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23779734.0000 - mse: 23779734.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 24014626.0000 - mse: 24014626.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25100504.0000 - mse: 25100504.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23996946.0000 - mse: 23996946.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25114082.0000 - mse: 25114082.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23875792.0000 - mse: 23875792.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23870774.0000 - mse: 23870774.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23093002.0000 - mse: 23093002.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23649022.0000 - mse: 23649022.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24139232.0000 - mse: 24139232.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23933114.0000 - mse: 23933114.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24042568.0000 - mse: 24042568.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23991856.0000 - mse: 23991856.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24077160.0000 - mse: 24077160.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23655322.0000 - mse: 23655322.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23382248.0000 - mse: 23382248.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23278216.0000 - mse: 23278216.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24643386.0000 - mse: 24643386.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23428526.0000 - mse: 23428526.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23728848.0000 - mse: 23728848.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23620396.0000 - mse: 23620396.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24096706.0000 - mse: 24096706.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23806386.0000 - mse: 23806386.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23567704.0000 - mse: 23567704.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24299284.0000 - mse: 24299284.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24490226.0000 - mse: 24490226.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24028244.0000 - mse: 24028244.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23999010.0000 - mse: 23999010.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23797436.0000 - mse: 23797436.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23267688.0000 - mse: 23267688.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23240898.0000 - mse: 23240898.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24624114.0000 - mse: 24624114.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23686504.0000 - mse: 23686504.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23491662.0000 - mse: 23491662.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23672054.0000 - mse: 23672054.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23426150.0000 - mse: 23426150.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23669148.0000 - mse: 23669148.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23648904.0000 - mse: 23648904.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23534918.0000 - mse: 23534918.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23534030.0000 - mse: 23534030.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23792652.0000 - mse: 23792652.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23390890.0000 - mse: 23390890.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24624494.0000 - mse: 24624494.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23502004.0000 - mse: 23502004.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23179746.0000 - mse: 23179746.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23883970.0000 - mse: 23883970.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23483698.0000 - mse: 23483698.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25122046.0000 - mse: 25122046.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25619946.0000 - mse: 25619946.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24101258.0000 - mse: 24101258.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23213606.0000 - mse: 23213606.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23988564.0000 - mse: 23988564.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22751046.0000 - mse: 22751046.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25036400.0000 - mse: 25036400.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23410322.0000 - mse: 23410322.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24213736.0000 - mse: 24213736.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24208880.0000 - mse: 24208880.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25696430.0000 - mse: 25696430.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23954376.0000 - mse: 23954376.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24714264.0000 - mse: 24714264.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24138336.0000 - mse: 24138336.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24264292.0000 - mse: 24264292.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24469502.0000 - mse: 24469502.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24092812.0000 - mse: 24092812.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23612224.0000 - mse: 23612224.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23521838.0000 - mse: 23521838.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24756532.0000 - mse: 24756532.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23982218.0000 - mse: 23982218.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23716416.0000 - mse: 23716416.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23518612.0000 - mse: 23518612.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24558652.0000 - mse: 24558652.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23639568.0000 - mse: 23639568.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24450218.0000 - mse: 24450218.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23478928.0000 - mse: 23478928.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23313260.0000 - mse: 23313260.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 24286622.0000 - mse: 24286622.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24653888.0000 - mse: 24653888.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23616026.0000 - mse: 23616026.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24060720.0000 - mse: 24060720.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25341208.0000 - mse: 25341208.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24637360.0000 - mse: 24637360.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24868640.0000 - mse: 24868640.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24294074.0000 - mse: 24294074.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24679356.0000 - mse: 24679356.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24034912.0000 - mse: 24034912.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23260836.0000 - mse: 23260836.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23844578.0000 - mse: 23844578.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22435760.0000 - mse: 22435760.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23536412.0000 - mse: 23536412.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23668522.0000 - mse: 23668522.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24204838.0000 - mse: 24204838.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23659964.0000 - mse: 23659964.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24402208.0000 - mse: 24402208.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23448862.0000 - mse: 23448862.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23843690.0000 - mse: 23843690.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23758574.0000 - mse: 23758574.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23961230.0000 - mse: 23961230.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24191018.0000 - mse: 24191018.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24608282.0000 - mse: 24608282.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23245358.0000 - mse: 23245358.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23537078.0000 - mse: 23537078.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25175350.0000 - mse: 25175350.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23560942.0000 - mse: 23560942.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25353868.0000 - mse: 25353868.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23396090.0000 - mse: 23396090.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23597514.0000 - mse: 23597514.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24077000.0000 - mse: 24077000.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23991942.0000 - mse: 23991942.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23444856.0000 - mse: 23444856.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23624420.0000 - mse: 23624420.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23839158.0000 - mse: 23839158.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25333082.0000 - mse: 25333082.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23693948.0000 - mse: 23693948.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23150924.0000 - mse: 23150924.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23920168.0000 - mse: 23920168.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23746652.0000 - mse: 23746652.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23630156.0000 - mse: 23630156.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24039142.0000 - mse: 24039142.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25017766.0000 - mse: 25017766.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23972294.0000 - mse: 23972294.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23533408.0000 - mse: 23533408.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24046736.0000 - mse: 24046736.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24177892.0000 - mse: 24177892.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22849608.0000 - mse: 22849608.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24540592.0000 - mse: 24540592.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22921634.0000 - mse: 22921634.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 82193104.0000 - mse: 82193104.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30389594.0000 - mse: 30389594.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27244768.0000 - mse: 27244768.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26026546.0000 - mse: 26026546.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28579836.0000 - mse: 28579836.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26558196.0000 - mse: 26558196.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27098984.0000 - mse: 27098984.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27311446.0000 - mse: 27311446.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26743394.0000 - mse: 26743394.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25642088.0000 - mse: 25642088.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27168346.0000 - mse: 27168346.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26330546.0000 - mse: 26330546.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28557630.0000 - mse: 28557630.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27377054.0000 - mse: 27377054.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26717810.0000 - mse: 26717810.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27884216.0000 - mse: 27884216.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27314764.0000 - mse: 27314764.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27515632.0000 - mse: 27515632.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25921844.0000 - mse: 25921844.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26763860.0000 - mse: 26763860.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26286192.0000 - mse: 26286192.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26396202.0000 - mse: 26396202.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28365734.0000 - mse: 28365734.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26491316.0000 - mse: 26491316.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27986060.0000 - mse: 27986060.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25968038.0000 - mse: 25968038.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26428762.0000 - mse: 26428762.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26978550.0000 - mse: 26978550.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28034348.0000 - mse: 28034348.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27354054.0000 - mse: 27354054.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 29768230.0000 - mse: 29768230.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27556874.0000 - mse: 27556874.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26651378.0000 - mse: 26651378.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26986170.0000 - mse: 26986170.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26801836.0000 - mse: 26801836.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27333288.0000 - mse: 27333288.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28246190.0000 - mse: 28246190.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26911118.0000 - mse: 26911118.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27575228.0000 - mse: 27575228.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28447924.0000 - mse: 28447924.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27762370.0000 - mse: 27762370.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28564358.0000 - mse: 28564358.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26723152.0000 - mse: 26723152.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26967946.0000 - mse: 26967946.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25545330.0000 - mse: 25545330.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25853394.0000 - mse: 25853394.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26939908.0000 - mse: 26939908.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27210036.0000 - mse: 27210036.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26993416.0000 - mse: 26993416.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28411262.0000 - mse: 28411262.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28156606.0000 - mse: 28156606.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27296046.0000 - mse: 27296046.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27177630.0000 - mse: 27177630.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26194358.0000 - mse: 26194358.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27218536.0000 - mse: 27218536.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27624718.0000 - mse: 27624718.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27000888.0000 - mse: 27000888.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28715978.0000 - mse: 28715978.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25914780.0000 - mse: 25914780.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27120432.0000 - mse: 27120432.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26879538.0000 - mse: 26879538.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27709114.0000 - mse: 27709114.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28250168.0000 - mse: 28250168.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26140290.0000 - mse: 26140290.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27524670.0000 - mse: 27524670.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25544986.0000 - mse: 25544986.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29991374.0000 - mse: 29991374.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29020124.0000 - mse: 29020124.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27026132.0000 - mse: 27026132.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26305438.0000 - mse: 26305438.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28259842.0000 - mse: 28259842.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27089050.0000 - mse: 27089050.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28004630.0000 - mse: 28004630.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29023462.0000 - mse: 29023464.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26549152.0000 - mse: 26549152.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 26792382.0000 - mse: 26792382.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27720496.0000 - mse: 27720496.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27418344.0000 - mse: 27418344.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25973936.0000 - mse: 25973936.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25674708.0000 - mse: 25674708.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26422554.0000 - mse: 26422554.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29799570.0000 - mse: 29799570.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27039990.0000 - mse: 27039990.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28824204.0000 - mse: 28824204.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26702662.0000 - mse: 26702662.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26048842.0000 - mse: 26048842.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26790998.0000 - mse: 26790998.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26817168.0000 - mse: 26817168.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27785758.0000 - mse: 27785758.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29810072.0000 - mse: 29810072.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27529356.0000 - mse: 27529356.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26457892.0000 - mse: 26457892.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27306548.0000 - mse: 27306548.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27052186.0000 - mse: 27052186.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26905002.0000 - mse: 26905002.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27468228.0000 - mse: 27468228.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29869346.0000 - mse: 29869346.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29567880.0000 - mse: 29567880.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 28911892.0000 - mse: 28911892.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26701316.0000 - mse: 26701316.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28077152.0000 - mse: 28077152.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26756562.0000 - mse: 26756562.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27474828.0000 - mse: 27474828.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25987526.0000 - mse: 25987526.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27854540.0000 - mse: 27854540.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26435050.0000 - mse: 26435050.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29292588.0000 - mse: 29292588.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26838668.0000 - mse: 26838668.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26831900.0000 - mse: 26831900.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27440726.0000 - mse: 27440726.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28349396.0000 - mse: 28349396.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27175170.0000 - mse: 27175170.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26959840.0000 - mse: 26959840.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25949696.0000 - mse: 25949696.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26728812.0000 - mse: 26728812.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27473884.0000 - mse: 27473884.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26696364.0000 - mse: 26696364.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 29450828.0000 - mse: 29450828.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25251790.0000 - mse: 25251790.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26275518.0000 - mse: 26275518.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26204540.0000 - mse: 26204540.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25776740.0000 - mse: 25776740.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26704898.0000 - mse: 26704898.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27191568.0000 - mse: 27191568.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26729314.0000 - mse: 26729314.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28766994.0000 - mse: 28766994.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25869656.0000 - mse: 25869656.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26433498.0000 - mse: 26433498.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28045902.0000 - mse: 28045902.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26925402.0000 - mse: 26925402.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25594426.0000 - mse: 25594426.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27794430.0000 - mse: 27794430.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28783112.0000 - mse: 28783112.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26251856.0000 - mse: 26251856.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28881716.0000 - mse: 28881716.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31022766.0000 - mse: 31022766.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28089814.0000 - mse: 28089814.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28895516.0000 - mse: 28895516.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27160024.0000 - mse: 27160024.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26333838.0000 - mse: 26333838.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26856134.0000 - mse: 26856134.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 29741454.0000 - mse: 29741454.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27097210.0000 - mse: 27097210.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26681248.0000 - mse: 26681248.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26139732.0000 - mse: 26139732.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26226220.0000 - mse: 26226220.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28639642.0000 - mse: 28639642.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26631316.0000 - mse: 26631316.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26204690.0000 - mse: 26204690.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 29351002.0000 - mse: 29351002.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28531978.0000 - mse: 28531978.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28776112.0000 - mse: 28776112.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26058390.0000 - mse: 26058390.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26845830.0000 - mse: 26845830.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27349482.0000 - mse: 27349482.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28523594.0000 - mse: 28523594.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26569082.0000 - mse: 26569082.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26325616.0000 - mse: 26325616.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28643960.0000 - mse: 28643960.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28579886.0000 - mse: 28579886.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28115452.0000 - mse: 28115452.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26264760.0000 - mse: 26264760.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28554280.0000 - mse: 28554280.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28236316.0000 - mse: 28236316.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28011500.0000 - mse: 28011500.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25946302.0000 - mse: 25946302.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26173260.0000 - mse: 26173260.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26304034.0000 - mse: 26304034.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28919830.0000 - mse: 28919830.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 964us/step - loss: 26270648.0000 - mse: 26270648.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 901us/step - loss: 26288110.0000 - mse: 26288110.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26287956.0000 - mse: 26287956.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 819us/step - loss: 29158704.0000 - mse: 29158704.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 851us/step - loss: 31489802.0000 - mse: 31489802.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26915458.0000 - mse: 26915458.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27760130.0000 - mse: 27760130.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25661656.0000 - mse: 25661656.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26523572.0000 - mse: 26523572.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27563838.0000 - mse: 27563838.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28514562.0000 - mse: 28514562.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28103920.0000 - mse: 28103920.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27601964.0000 - mse: 27601964.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26565672.0000 - mse: 26565672.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25988950.0000 - mse: 25988950.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 30672114.0000 - mse: 30672114.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26827834.0000 - mse: 26827834.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27623356.0000 - mse: 27623356.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26820348.0000 - mse: 26820348.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26983142.0000 - mse: 26983142.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28552634.0000 - mse: 28552634.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25950090.0000 - mse: 25950090.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27641056.0000 - mse: 27641056.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27002530.0000 - mse: 27002530.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26837060.0000 - mse: 26837060.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26823280.0000 - mse: 26823280.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26942366.0000 - mse: 26942366.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27712626.0000 - mse: 27712626.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27647436.0000 - mse: 27647436.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 971us/step - loss: 26967932.0000 - mse: 26967932.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27459148.0000 - mse: 27459148.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 68085336.0000 - mse: 68085336.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 27032038.0000 - mse: 27032038.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24502634.0000 - mse: 24502634.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25900946.0000 - mse: 25900946.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24432742.0000 - mse: 24432742.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24077628.0000 - mse: 24077628.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24250864.0000 - mse: 24250864.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25305520.0000 - mse: 25305520.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23558426.0000 - mse: 23558426.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24515134.0000 - mse: 24515134.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24076076.0000 - mse: 24076076.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24279330.0000 - mse: 24279330.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23774036.0000 - mse: 23774036.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 955us/step - loss: 24391762.0000 - mse: 24391762.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25288798.0000 - mse: 25288798.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24782226.0000 - mse: 24782226.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24031570.0000 - mse: 24031570.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24590034.0000 - mse: 24590034.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25575844.0000 - mse: 25575844.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23534584.0000 - mse: 23534584.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 953us/step - loss: 24865868.0000 - mse: 24865868.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 849us/step - loss: 24411602.0000 - mse: 24411602.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 960us/step - loss: 24348148.0000 - mse: 24348148.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 943us/step - loss: 25787504.0000 - mse: 25787504.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24331642.0000 - mse: 24331642.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25237112.0000 - mse: 25237112.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24859894.0000 - mse: 24859894.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26004462.0000 - mse: 26004462.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24294194.0000 - mse: 24294194.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 28535626.0000 - mse: 28535626.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23968862.0000 - mse: 23968862.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25002988.0000 - mse: 25002988.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25175228.0000 - mse: 25175228.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25338848.0000 - mse: 25338848.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24402576.0000 - mse: 24402576.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24840064.0000 - mse: 24840064.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24530974.0000 - mse: 24530974.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24954994.0000 - mse: 24954994.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24720890.0000 - mse: 24720890.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25477780.0000 - mse: 25477780.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24735898.0000 - mse: 24735898.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25090336.0000 - mse: 25090336.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25309904.0000 - mse: 25309904.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25798568.0000 - mse: 25798568.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24151520.0000 - mse: 24151520.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25195508.0000 - mse: 25195508.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25620482.0000 - mse: 25620482.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24155144.0000 - mse: 24155144.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23771744.0000 - mse: 23771744.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24433390.0000 - mse: 24433390.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25178404.0000 - mse: 25178404.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24488696.0000 - mse: 24488696.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24112072.0000 - mse: 24112072.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24019260.0000 - mse: 24019260.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24761944.0000 - mse: 24761944.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23844868.0000 - mse: 23844868.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23854606.0000 - mse: 23854606.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24443418.0000 - mse: 24443418.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23377402.0000 - mse: 23377402.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25094698.0000 - mse: 25094698.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24859222.0000 - mse: 24859222.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23631716.0000 - mse: 23631716.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24088974.0000 - mse: 24088974.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23939104.0000 - mse: 23939104.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25703272.0000 - mse: 25703272.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24917760.0000 - mse: 24917760.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24275996.0000 - mse: 24275996.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25122566.0000 - mse: 25122566.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23966794.0000 - mse: 23966794.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24617240.0000 - mse: 24617240.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26553326.0000 - mse: 26553326.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25509712.0000 - mse: 25509712.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25104972.0000 - mse: 25104972.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23996848.0000 - mse: 23996848.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24498432.0000 - mse: 24498432.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 24186972.0000 - mse: 24186972.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24357484.0000 - mse: 24357484.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24069956.0000 - mse: 24069956.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24928578.0000 - mse: 24928578.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26203522.0000 - mse: 26203522.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25484884.0000 - mse: 25484884.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25260400.0000 - mse: 25260400.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23582318.0000 - mse: 23582318.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25458252.0000 - mse: 25458252.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24547254.0000 - mse: 24547254.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24765280.0000 - mse: 24765280.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26651228.0000 - mse: 26651228.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25593696.0000 - mse: 25593696.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24077652.0000 - mse: 24077652.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27261684.0000 - mse: 27261684.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25054744.0000 - mse: 25054744.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25529468.0000 - mse: 25529468.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23988056.0000 - mse: 23988056.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25747428.0000 - mse: 25747428.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23880016.0000 - mse: 23880016.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23904882.0000 - mse: 23904882.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23734104.0000 - mse: 23734104.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23466272.0000 - mse: 23466272.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27095268.0000 - mse: 27095268.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24360390.0000 - mse: 24360390.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25091128.0000 - mse: 25091128.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26384718.0000 - mse: 26384718.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24233016.0000 - mse: 24233016.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23143656.0000 - mse: 23143656.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23820592.0000 - mse: 23820592.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26189428.0000 - mse: 26189428.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24727584.0000 - mse: 24727584.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25091996.0000 - mse: 25091996.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26481622.0000 - mse: 26481622.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24810654.0000 - mse: 24810654.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23669200.0000 - mse: 23669200.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23492008.0000 - mse: 23492008.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25319868.0000 - mse: 25319868.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24868474.0000 - mse: 24868474.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23006278.0000 - mse: 23006278.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26239280.0000 - mse: 26239280.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25531276.0000 - mse: 25531276.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24856832.0000 - mse: 24856832.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24060854.0000 - mse: 24060854.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25832848.0000 - mse: 25832848.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24327490.0000 - mse: 24327490.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23772242.0000 - mse: 23772242.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23309740.0000 - mse: 23309740.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24538690.0000 - mse: 24538690.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24609152.0000 - mse: 24609152.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25884328.0000 - mse: 25884328.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23782196.0000 - mse: 23782196.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25271674.0000 - mse: 25271674.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23441834.0000 - mse: 23441834.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24816850.0000 - mse: 24816850.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26566266.0000 - mse: 26566266.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24102030.0000 - mse: 24102030.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24637526.0000 - mse: 24637526.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23904862.0000 - mse: 23904862.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27357018.0000 - mse: 27357018.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24217802.0000 - mse: 24217802.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23811056.0000 - mse: 23811056.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25213544.0000 - mse: 25213544.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24494300.0000 - mse: 24494300.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23940624.0000 - mse: 23940624.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24080252.0000 - mse: 24080252.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26094134.0000 - mse: 26094134.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25104366.0000 - mse: 25104366.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25213306.0000 - mse: 25213306.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23581988.0000 - mse: 23581988.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24877404.0000 - mse: 24877404.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25477378.0000 - mse: 25477378.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23643614.0000 - mse: 23643614.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 993us/step - loss: 24332872.0000 - mse: 24332872.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 25346590.0000 - mse: 25346590.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23702650.0000 - mse: 23702650.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25197512.0000 - mse: 25197512.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24554100.0000 - mse: 24554100.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 28475068.0000 - mse: 28475066.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24297814.0000 - mse: 24297814.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25650576.0000 - mse: 25650576.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26740792.0000 - mse: 26740792.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25865548.0000 - mse: 25865548.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23779628.0000 - mse: 23779628.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23897462.0000 - mse: 23897462.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23406552.0000 - mse: 23406552.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25691344.0000 - mse: 25691344.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23771418.0000 - mse: 23771418.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 26425748.0000 - mse: 26425748.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23943868.0000 - mse: 23943868.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24673828.0000 - mse: 24673828.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26602998.0000 - mse: 26602998.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 27209590.0000 - mse: 27209590.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24261996.0000 - mse: 24261996.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25747390.0000 - mse: 25747390.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25083064.0000 - mse: 25083064.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24065218.0000 - mse: 24065218.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24731866.0000 - mse: 24731866.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24672890.0000 - mse: 24672890.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24105272.0000 - mse: 24105272.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23911220.0000 - mse: 23911220.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24420380.0000 - mse: 24420380.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24039056.0000 - mse: 24039056.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26189540.0000 - mse: 26189540.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23695084.0000 - mse: 23695084.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23410792.0000 - mse: 23410792.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24315856.0000 - mse: 24315856.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25880550.0000 - mse: 25880550.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23419480.0000 - mse: 23419480.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24692956.0000 - mse: 24692956.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26188132.0000 - mse: 26188132.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25011942.0000 - mse: 25011942.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24459670.0000 - mse: 24459670.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24901530.0000 - mse: 24901530.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23991050.0000 - mse: 23991050.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24632744.0000 - mse: 24632744.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26434748.0000 - mse: 26434748.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23889532.0000 - mse: 23889532.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25673444.0000 - mse: 25673444.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23742388.0000 - mse: 23742388.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24065440.0000 - mse: 24065440.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 996us/step - loss: 24476698.0000 - mse: 24476698.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24350528.0000 - mse: 24350528.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25146766.0000 - mse: 25146766.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25040100.0000 - mse: 25040100.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 105962728.0000 - mse: 105962728.0000\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31679072.0000 - mse: 31679072.0000\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 26040902.0000 - mse: 26040902.0000\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25345208.0000 - mse: 25345208.0000\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24016304.0000 - mse: 24016304.0000\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23939952.0000 - mse: 23939952.0000\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22989468.0000 - mse: 22989468.0000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23768424.0000 - mse: 23768424.0000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23799254.0000 - mse: 23799254.0000\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23080020.0000 - mse: 23080020.0000\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23334924.0000 - mse: 23334924.0000\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24316454.0000 - mse: 24316454.0000\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22478582.0000 - mse: 22478582.0000\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23640330.0000 - mse: 23640330.0000\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23506836.0000 - mse: 23506836.0000\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22890280.0000 - mse: 22890280.0000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22107178.0000 - mse: 22107178.0000\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23026708.0000 - mse: 23026708.0000\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23528028.0000 - mse: 23528028.0000\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23988110.0000 - mse: 23988110.0000\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24230818.0000 - mse: 24230818.0000\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24667228.0000 - mse: 24667228.0000\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23876990.0000 - mse: 23876990.0000\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23432172.0000 - mse: 23432172.0000\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22848458.0000 - mse: 22848458.0000\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24410048.0000 - mse: 24410048.0000\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23266070.0000 - mse: 23266070.0000\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23065286.0000 - mse: 23065286.0000\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24325288.0000 - mse: 24325288.0000\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23603292.0000 - mse: 23603292.0000\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23458964.0000 - mse: 23458964.0000\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23301314.0000 - mse: 23301314.0000\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22156718.0000 - mse: 22156718.0000\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23027866.0000 - mse: 23027866.0000\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22366240.0000 - mse: 22366240.0000\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22969142.0000 - mse: 22969142.0000\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22548464.0000 - mse: 22548464.0000\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23115540.0000 - mse: 23115540.0000\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24324252.0000 - mse: 24324252.0000\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24501256.0000 - mse: 24501256.0000\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23136682.0000 - mse: 23136682.0000\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22539808.0000 - mse: 22539808.0000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24345604.0000 - mse: 24345604.0000\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23149756.0000 - mse: 23149756.0000\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22812364.0000 - mse: 22812364.0000\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22896686.0000 - mse: 22896686.0000\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22920402.0000 - mse: 22920402.0000\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23517526.0000 - mse: 23517526.0000\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23577730.0000 - mse: 23577730.0000\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22871710.0000 - mse: 22871710.0000\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23995784.0000 - mse: 23995784.0000\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24127436.0000 - mse: 24127436.0000\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25378682.0000 - mse: 25378682.0000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23342590.0000 - mse: 23342590.0000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23304706.0000 - mse: 23304706.0000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23119292.0000 - mse: 23119292.0000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23890828.0000 - mse: 23890828.0000\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24213410.0000 - mse: 24213410.0000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23303118.0000 - mse: 23303118.0000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23058500.0000 - mse: 23058500.0000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23416942.0000 - mse: 23416942.0000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23788896.0000 - mse: 23788896.0000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22481596.0000 - mse: 22481596.0000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23962126.0000 - mse: 23962126.0000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23787498.0000 - mse: 23787498.0000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22929572.0000 - mse: 22929572.0000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23477564.0000 - mse: 23477564.0000\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23983990.0000 - mse: 23983990.0000\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23798098.0000 - mse: 23798098.0000\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22871134.0000 - mse: 22871134.0000\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23421056.0000 - mse: 23421056.0000\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23273114.0000 - mse: 23273116.0000\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23559184.0000 - mse: 23559184.0000\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23412502.0000 - mse: 23412502.0000\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22166546.0000 - mse: 22166546.0000\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 23764132.0000 - mse: 23764132.0000\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24389612.0000 - mse: 24389612.0000\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23000474.0000 - mse: 23000474.0000\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22891006.0000 - mse: 22891006.0000\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23169378.0000 - mse: 23169378.0000\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23143302.0000 - mse: 23143302.0000\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23730208.0000 - mse: 23730208.0000\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22330458.0000 - mse: 22330458.0000\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24421894.0000 - mse: 24421894.0000\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22954252.0000 - mse: 22954252.0000\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22414370.0000 - mse: 22414370.0000\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22414074.0000 - mse: 22414074.0000\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23968090.0000 - mse: 23968090.0000\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25724230.0000 - mse: 25724230.0000\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24117334.0000 - mse: 24117334.0000\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23021878.0000 - mse: 23021878.0000\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23156294.0000 - mse: 23156294.0000\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24271544.0000 - mse: 24271544.0000\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24117802.0000 - mse: 24117802.0000\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22569390.0000 - mse: 22569390.0000\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22851992.0000 - mse: 22851992.0000\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23262098.0000 - mse: 23262098.0000\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24147142.0000 - mse: 24147142.0000\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23980672.0000 - mse: 23980672.0000\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22626580.0000 - mse: 22626580.0000\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25113012.0000 - mse: 25113012.0000\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24197630.0000 - mse: 24197630.0000\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23254368.0000 - mse: 23254368.0000\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23714638.0000 - mse: 23714638.0000\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23674368.0000 - mse: 23674368.0000\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22642132.0000 - mse: 22642132.0000\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24801176.0000 - mse: 24801176.0000\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25097272.0000 - mse: 25097272.0000\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23604846.0000 - mse: 23604846.0000\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22729270.0000 - mse: 22729270.0000\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24001718.0000 - mse: 24001718.0000\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23007144.0000 - mse: 23007144.0000\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23585446.0000 - mse: 23585446.0000\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23171932.0000 - mse: 23171932.0000\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25618948.0000 - mse: 25618948.0000\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23579550.0000 - mse: 23579550.0000\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23472186.0000 - mse: 23472186.0000\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22807014.0000 - mse: 22807014.0000\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23315578.0000 - mse: 23315578.0000\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23825010.0000 - mse: 23825010.0000\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23301574.0000 - mse: 23301574.0000\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24824562.0000 - mse: 24824562.0000\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22840218.0000 - mse: 22840218.0000\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23339628.0000 - mse: 23339628.0000\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24263372.0000 - mse: 24263372.0000\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25539094.0000 - mse: 25539094.0000\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23032550.0000 - mse: 23032550.0000\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23165382.0000 - mse: 23165382.0000\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 23299304.0000 - mse: 23299304.0000\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23214696.0000 - mse: 23214696.0000\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23545068.0000 - mse: 23545068.0000\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23729286.0000 - mse: 23729286.0000\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22615004.0000 - mse: 22615004.0000\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22465534.0000 - mse: 22465534.0000\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24620562.0000 - mse: 24620562.0000\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23140780.0000 - mse: 23140780.0000\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23495550.0000 - mse: 23495550.0000\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24386522.0000 - mse: 24386522.0000\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22983144.0000 - mse: 22983144.0000\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24441672.0000 - mse: 24441672.0000\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23100358.0000 - mse: 23100358.0000\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22569512.0000 - mse: 22569512.0000\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22563038.0000 - mse: 22563038.0000\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24988562.0000 - mse: 24988562.0000\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22504080.0000 - mse: 22504080.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24227362.0000 - mse: 24227362.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22510992.0000 - mse: 22510992.0000\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23112064.0000 - mse: 23112064.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22595908.0000 - mse: 22595908.0000\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 24106128.0000 - mse: 24106128.0000\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23742494.0000 - mse: 23742494.0000\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23041636.0000 - mse: 23041636.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23546760.0000 - mse: 23546760.0000\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23767026.0000 - mse: 23767026.0000\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23518362.0000 - mse: 23518362.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24384394.0000 - mse: 24384394.0000\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 22830932.0000 - mse: 22830932.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25351752.0000 - mse: 25351752.0000\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23861892.0000 - mse: 23861892.0000\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24931636.0000 - mse: 24931636.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23348070.0000 - mse: 23348070.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23955746.0000 - mse: 23955746.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22391072.0000 - mse: 22391072.0000\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24544714.0000 - mse: 24544714.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23107676.0000 - mse: 23107676.0000\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23004850.0000 - mse: 23004850.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23168686.0000 - mse: 23168686.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23691242.0000 - mse: 23691242.0000\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24009172.0000 - mse: 24009172.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23991898.0000 - mse: 23991898.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23699462.0000 - mse: 23699462.0000\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23060722.0000 - mse: 23060722.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24125200.0000 - mse: 24125200.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22941342.0000 - mse: 22941342.0000\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23787400.0000 - mse: 23787400.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23669108.0000 - mse: 23669108.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 23257972.0000 - mse: 23257972.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22211310.0000 - mse: 22211310.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22190506.0000 - mse: 22190506.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23578100.0000 - mse: 23578100.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24138258.0000 - mse: 24138258.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24861714.0000 - mse: 24861714.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23926766.0000 - mse: 23926766.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24130770.0000 - mse: 24130770.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23749046.0000 - mse: 23749046.0000\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24349912.0000 - mse: 24349912.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23115948.0000 - mse: 23115948.0000\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 25188724.0000 - mse: 25188724.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 24429806.0000 - mse: 24429806.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22847318.0000 - mse: 22847318.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23604206.0000 - mse: 23604206.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23732724.0000 - mse: 23732724.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 25817246.0000 - mse: 25817246.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22736464.0000 - mse: 22736464.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22603952.0000 - mse: 22603952.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24225938.0000 - mse: 24225938.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23674874.0000 - mse: 23674874.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 24461690.0000 - mse: 24461690.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 22836124.0000 - mse: 22836124.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 23081922.0000 - mse: 23081922.0000\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "R2 train 0.6888367965702598\n",
      "MAE Train 4386.80140956459\n",
      "RMSE Train 5502.477744687565\n"
     ]
    }
   ],
   "source": [
    "#Diseñar modelo con métricas optimizadas\n",
    "\n",
    "def create_model(lr=0.1,momentum=0.4):\n",
    "    # Neural network architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12,activation='tanh',input_dim=5))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    \n",
    "    # Optimizer configuration\n",
    "    opt = keras.optimizers.SGD(lr=lr,momentum=momentum)\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 100\n",
    "\n",
    "model_search = KerasRegressor(build_fn=create_model,epochs=epochs)\n",
    "\n",
    "\n",
    "#Entreno modelo optimizado\n",
    "model_search.fit(X_train, y_train)\n",
    "\n",
    "#Hacer el cross validation y probar con el train\n",
    "r2_nn= (cross_val_score(model_search, X_train,y_train, cv=kfold,  scoring='r2')).mean()\n",
    "mae_nn= -(cross_val_score(model_search, X_train,y_train, cv=kfold,  scoring='neg_mean_absolute_error')).mean()\n",
    "mse_nn= (-cross_val_score(model_search, X_train,y_train, cv=kfold,  scoring='neg_root_mean_squared_error')).mean()\n",
    "\n",
    "#Performance en el train\n",
    "print(\"R2 train\", r2_nn)\n",
    "print(\"MAE Train\", mae_nn)\n",
    "print(\"RMSE Train\", mse_nn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>3707.119022</td>\n",
       "      <td>4826.175087</td>\n",
       "      <td>0.716024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model          MAE         RMSE        R2\n",
       "0  Neural Network  3707.119022  4826.175087  0.716024"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance en el test\n",
    "y_pred = model_search.predict(X_test)\n",
    "\n",
    "mae_nn=mean_absolute_error(y_test,y_pred)\n",
    "mse_nn=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2_nn=r2_score(y_test,y_pred)\n",
    "\n",
    "results_nn = pd.DataFrame([['Neural Network', mae_nn,mse_nn,r2_nn]],columns=['Model', 'MAE', 'RMSE', 'R2'])\n",
    "results_nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>3666.939818</td>\n",
       "      <td>2842.934786</td>\n",
       "      <td>0.836061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>3666.979515</td>\n",
       "      <td>2844.436399</td>\n",
       "      <td>0.836057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>2561.377387</td>\n",
       "      <td>1836.106102</td>\n",
       "      <td>0.920012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree</td>\n",
       "      <td>2880.276684</td>\n",
       "      <td>1960.984898</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>3724.912323</td>\n",
       "      <td>2814.094942</td>\n",
       "      <td>0.830836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN</td>\n",
       "      <td>4826.175087</td>\n",
       "      <td>3707.119022</td>\n",
       "      <td>0.716024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo         RMSE          MAE        R2\n",
       "0     LR  3666.939818  2842.934786  0.836061\n",
       "1  Ridge  3666.979515  2844.436399  0.836057\n",
       "2     RF  2561.377387  1836.106102  0.920012\n",
       "3   Tree  2880.276684  1960.984898  0.898855\n",
       "4    SVR  3724.912323  2814.094942  0.830836\n",
       "5     NN  4826.175087  3707.119022  0.716024"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compar_cross = {'Modelo': ['LR', 'Ridge', 'RF','Tree', ' SVR', 'NN'], 'RMSE': [rmse_lr, rmse_ridge, rmse_rf, rmse_tree,rmse_svr, mse_nn],\n",
    "                    'MAE':[mae_lr, mae_ridge, mae_rf, mae_tree,mae_svr, mae_nn],\n",
    "                    'R2':[r2_lr, r2_ridge, r2_rf, r2_tree,r2_svr, r2_nn]} \n",
    "data_compar_cross = pd.DataFrame(data_compar_cross)\n",
    "data_compar_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos datos, el mejor modelo el el Random Forest (Bosque Aleatorio). \n",
    "\n",
    "Por lo tanto utilizaremos este modelo para predecir datos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>miles</th>\n",
       "      <th>debt</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>5999</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  miles  debt  income\n",
       "0   27       0     30  5999    7000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear nuevos datos\n",
    "X_new  = pd.DataFrame([[27, 0, 30, 5999, 7000]], columns=['age', 'gender', 'miles', 'debt', 'income'])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\anaconda3\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  return\n"
     ]
    }
   ],
   "source": [
    "# ¿Cuál sería el valor del carro?\n",
    "ynew = new_model_RF.predict(X_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor del carro sería [28539.81413163]\n"
     ]
    }
   ],
   "source": [
    "print('el valor del carro sería', ynew)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
